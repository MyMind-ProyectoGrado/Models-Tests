# EvaluaciÃ³n de Modelos de TranscripciÃ³n de Voz

## ğŸ“‹ DescripciÃ³n del Proyecto

Este repositorio contiene la evaluaciÃ³n comparativa de diferentes modelos de **Automatic Speech Recognition (ASR)** para el proyecto **myMind** de la **Pontificia Universidad Javeriana**. El objetivo es identificar el modelo mÃ¡s eficiente y preciso para la transcripciÃ³n de audio en espaÃ±ol.

**Autor:** Juan JosÃ© GÃ³mez Arenas  
**InstituciÃ³n:** Pontificia Universidad Javeriana  
**Proyecto:** myMind

## ğŸ¯ Objetivo

Evaluar y comparar el rendimiento de mÃºltiples modelos de transcripciÃ³n automÃ¡tica de voz para seleccionar la mejor opciÃ³n para la aplicaciÃ³n myMind, considerando factores como:

- **PrecisiÃ³n de transcripciÃ³n** (WER, WA, CER)
- **Velocidad de procesamiento** (WPM, tiempo de ejecuciÃ³n)
- **Recursos computacionales requeridos**
- **Compatibilidad con espaÃ±ol**

## ğŸ”§ Modelos Evaluados

### âœ… Modelos Implementados
1. **Whisper** (OpenAI)
   - `tiny`, `small`, `medium`
   - Modelo `large` omitido por limitaciones de recursos
2. **SpeechBrain**
   - Modelo preentrenado para espaÃ±ol
3. **Kaldi/Vosk**
   - VersiÃ³n pequeÃ±a y completa
4. **NeMo** (NVIDIA)
   - Modelo conformer transducer para espaÃ±ol
5. **Wav2Vec 2.0** (Facebook)
   - Modelos base, medium y large

### âŒ Modelos No Completados
- **WhisperX:** Pendiente de implementaciÃ³n
- **Qwen2Audio:** Modelo demasiado pesado para el entorno
- **Wav2Vec large:** Interrumpido por limitaciones computacionales

## ğŸ“Š MÃ©tricas de EvaluaciÃ³n

El sistema evalÃºa cada modelo usando las siguientes mÃ©tricas:

- **WER (Word Error Rate):** Tasa de errores de palabras
- **WA (Word Accuracy):** PrecisiÃ³n de palabras (1 - WER)
- **CER (Character Error Rate):** Tasa de errores de caracteres
- **WPM (Words Per Minute):** Velocidad de transcripciÃ³n
- **Tiempo de EjecuciÃ³n:** Tiempo total de procesamiento

## ğŸš€ ConfiguraciÃ³n del Entorno

### Prerrequisitos
```bash
# LibrerÃ­as principales
pip install jiwer librosa torch transformers
pip install openai-whisper speechbrain vosk
pip install nemo_toolkit['asr'] torchaudio pydub
```

### Estructura de Directorios
```
ğŸ“ Transcripcion/
â”œâ”€â”€ ğŸ“ Audios/                    # Archivos de audio (.wav)
â”œâ”€â”€ ğŸ“ Transcripciones_Manuales/  # Ground truth
â””â”€â”€ ğŸ“ Resultados/                # Resultados por modelo
    â”œâ”€â”€ ğŸ“ Whisper_tiny/
    â”œâ”€â”€ ğŸ“ Whisper_small/
    â”œâ”€â”€ ğŸ“ SpeechBrain/
    â”œâ”€â”€ ğŸ“ Kaldi_Vosk/
    â””â”€â”€ ğŸ“ Nemo/
```

## ğŸ’» Uso

### EjecuciÃ³n de Evaluaciones
```python
# Ejemplo para Whisper
python evaluate_whisper.py --model_size tiny --audio_dir /path/to/audios

# Ejemplo para SpeechBrain
python evaluate_speechbrain.py --audio_dir /path/to/audios

# Ejemplo para NeMo
python evaluate_nemo.py --model stt_es_conformer_transducer_large
```

### CÃ¡lculo de MÃ©tricas
```python
from jiwer import wer, cer

def calculate_metrics(reference, hypothesis, execution_time):
    word_error_rate = wer(reference, hypothesis)
    return {
        "WER": word_error_rate,
        "WA": 1 - word_error_rate,
        "CER": cer(reference, hypothesis),
        "WPM": words_per_minute(hypothesis),
        "Execution Time (s)": execution_time
    }
```

## ğŸ“ˆ Resultados Preliminares

### Observaciones Generales
- **Whisper** muestra consistencia entre sus versiones tiny y small
- **NeMo** ofrece buen rendimiento en espaÃ±ol
- **SpeechBrain** presenta resultados competitivos
- **Kaldi/Vosk** varÃ­a significativamente segÃºn la versiÃ³n del modelo

### Limitaciones Encontradas
- Modelos grandes requieren recursos computacionales significativos
- Algunos modelos presentan problemas de compatibilidad
- El entorno de Google Colab impone restricciones de memoria

## ğŸ› ï¸ Funciones Principales

### CÃ¡lculo de WPM
```python
def words_per_minute(text, audio_path):
    word_count = len(text.split())
    duration = librosa.get_duration(path=audio_path)
    return word_count / (duration / 60)
```

### TranscripciÃ³n con Manejo de Errores
```python
def transcribe_with_metrics(model, audio_path):
    start_time = time.time()
    try:
        transcript = model.transcribe(audio_path)
        execution_time = time.time() - start_time
        return transcript, execution_time
    except Exception as e:
        print(f"Error: {e}")
        return None, None
```

## ğŸ“‹ Archivos del Proyecto

- `PruebaModelosTranscripciÃ³n.ipynb` - Notebook principal con todas las evaluaciones
- `README.md` - Este archivo
- `/Audios/` - Dataset de archivos de audio para evaluaciÃ³n
- `/Resultados/` - Transcripciones y mÃ©tricas generadas

## ğŸ”¬ MetodologÃ­a

1. **PreparaciÃ³n de datos:** Audios en formato WAV
2. **TranscripciÃ³n manual:** Ground truth para comparaciÃ³n
3. **EvaluaciÃ³n sistemÃ¡tica:** Cada modelo procesa el mismo conjunto de audios
4. **CÃ¡lculo de mÃ©tricas:** ComparaciÃ³n automÃ¡tica con referencias
5. **AnÃ¡lisis de resultados:** IdentificaciÃ³n del mejor modelo

## ğŸš§ Trabajo Futuro

- [ ] Completar evaluaciÃ³n de WhisperX
- [ ] Implementar evaluaciÃ³n con modelos mÃ¡s ligeros de Qwen2Audio
- [ ] Optimizar uso de memoria para modelos grandes
- [ ] AnÃ¡lisis estadÃ­stico detallado de resultados
- [ ] ImplementaciÃ³n del modelo seleccionado en myMind

## ğŸ“ Contacto

**Juan JosÃ© GÃ³mez Arenas**  
Pontificia Universidad Javeriana  
Proyecto myMind

---

**Nota:** Este proyecto forma parte del desarrollo de la aplicaciÃ³n myMind para mejorar las capacidades de transcripciÃ³n automÃ¡tica de voz en espaÃ±ol.
