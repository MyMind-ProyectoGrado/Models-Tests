# myMind - EvaluaciÃ³n de Modelos de Reconocimiento de Voz

## ğŸ“‹ DescripciÃ³n del Proyecto

Este repositorio contiene la evaluaciÃ³n exhaustiva de diferentes modelos de reconocimiento automÃ¡tico de voz (ASR) y anÃ¡lisis de emociones/sentimientos para el proyecto **myMind** de la Pontificia Universidad Javeriana. El objetivo es seleccionar el modelo mÃ¡s adecuado para la transcripciÃ³n de audio en espaÃ±ol con las mejores mÃ©tricas de rendimiento y eficiencia.

## ğŸ¯ Objetivo

Evaluar y comparar el rendimiento de mÃºltiples modelos de ASR para determinar cuÃ¡l ofrece la mejor combinaciÃ³n de:
- **PrecisiÃ³n de transcripciÃ³n** (WER, CER, WA)
- **Velocidad de procesamiento** (WPM)
- **Eficiencia computacional** (tiempo de ejecuciÃ³n)

## ğŸ“ Estructura del Repositorio

```
â”œâ”€â”€ PruebaModelosTranscripciÃ³n.ipynb    # EvaluaciÃ³n de modelos ASR
â”œâ”€â”€ PruebaModelosEmociones.ipynb        # EvaluaciÃ³n de modelos de emociones/sentimientos
â”œâ”€â”€ Audios/                             # Dataset de archivos de audio (69 archivos .wav)
â”œâ”€â”€ Transcripciones_Manuales/           # Transcripciones de referencia (ground truth)
â””â”€â”€ Resultados/                         # Resultados y mÃ©tricas por modelo
    â”œâ”€â”€ Whisper_tiny/
    â”œâ”€â”€ Whisper_small/
    â”œâ”€â”€ Whisper_medium/
    â”œâ”€â”€ SpeechBrain/
    â”œâ”€â”€ Nemo/
    â”œâ”€â”€ Kaldi_Vosk/
    â””â”€â”€ ...
```

## ğŸ¤– Modelos Evaluados

### Modelos ASR (Reconocimiento de Voz)

| Modelo | Variante | Estado | DescripciÃ³n |
|--------|----------|--------|-------------|
| **Whisper** | tiny, small, medium | âœ… Evaluado | Modelo de OpenAI optimizado para espaÃ±ol |
| **WhisperX** | medium, large | âš ï¸ Parcial | VersiÃ³n optimizada con alineaciÃ³n temporal |
| **Wav2Vec 2.0** | base, medium, large | âš ï¸ Interrumpido | Modelo de Facebook para ASR |
| **SpeechBrain** | wav2vec2-commonvoice-es | âœ… Evaluado | Framework especializado en espaÃ±ol |
| **NeMo** | conformer-transducer-large | âœ… Evaluado | NVIDIA's toolkit para ASR |
| **Kaldi/Vosk** | small, complete | âœ… Evaluado | ImplementaciÃ³n tradicional de Kaldi |
| **Qwen2Audio** | 7B-Instruct | âŒ Fallido | LLM multimodal (limitaciones de RAM) |

### Modelos de Emociones/Sentimientos

- EvaluaciÃ³n de modelos pre-entrenados
- Fine-tuning para mejora de mÃ©tricas
- AnÃ¡lisis de accuracy, precisiÃ³n, recall y F1-score

## ğŸ“Š MÃ©tricas de EvaluaciÃ³n

### Para ASR:
- **WER (Word Error Rate)**: Tasa de errores de palabras
- **WA (Word Accuracy)**: PrecisiÃ³n en palabras (1 - WER)
- **CER (Character Error Rate)**: Tasa de errores de caracteres
- **WPM (Words Per Minute)**: Velocidad de transcripciÃ³n
- **Execution Time**: Tiempo de procesamiento

### Para Emociones:
- **Accuracy**: PrecisiÃ³n general del modelo
- **Precision**: PrecisiÃ³n por clase
- **Recall**: Sensibilidad por clase
- **F1-Score**: Media armÃ³nica de precisiÃ³n y recall

## ğŸš€ ConfiguraciÃ³n y Uso

### Requisitos Previos

```bash
# LibrerÃ­as principales
pip install openai-whisper
pip install jiwer librosa
pip install speechbrain transformers
pip install nemo_toolkit['asr']
pip install vosk
pip install torch torchaudio
```

### EjecuciÃ³n

1. **Preparar datos**: Colocar archivos de audio en `/Audios/` y transcripciones manuales en `/Transcripciones_Manuales/`

2. **Ejecutar evaluaciÃ³n ASR**:
   ```python
   # Abrir PruebaModelosTranscripciÃ³n.ipynb
   # Ejecutar celdas secuencialmente por modelo
   ```

3. **Ejecutar evaluaciÃ³n de emociones**:
   ```python
   # Abrir PruebaModelosEmociones.ipynb
   # Seguir el flujo de evaluaciÃ³n y fine-tuning
   ```

## ğŸ“ˆ Resultados Destacados

### Mejores Modelos ASR (Preliminar)

| Modelo | WER Promedio | WPM Promedio | Tiempo EjecuciÃ³n |
|--------|--------------|--------------|------------------|
| Whisper Small | ~0.15 | ~145 | ~30s |
| NeMo Conformer | ~0.12 | ~140 | ~15s |
| SpeechBrain | ~0.18 | ~95 | ~45s |

> **Nota**: Resultados basados en dataset de 69 archivos de audio en espaÃ±ol

### Consideraciones TÃ©cnicas

- **Whisper Large**: Descartado por limitaciones de RAM (>12GB requeridos)
- **Qwen2Audio**: No viable por consumo excesivo de memoria
- **Wav2Vec**: EvaluaciÃ³n interrumpida por problemas de compatibilidad

## âš ï¸ Limitaciones y DesafÃ­os

1. **Recursos Computacionales**: 
   - Modelos grandes requieren >12GB RAM
   - Tiempo de procesamiento extenso para algunos modelos

2. **Compatibilidad**:
   - Algunos modelos requieren versiones especÃ­ficas de dependencias
   - Problemas de compatibilidad entre frameworks

3. **Dataset**:
   - 69 archivos de audio en espaÃ±ol
   - Variabilidad en calidad y duraciÃ³n de grabaciones

## ğŸ‘¥ Equipo

**Juan JosÃ© GÃ³mez Arenas**  
*Pontificia Universidad Javeriana*  
*Proyecto myMind*

## ğŸ“ Notas de ImplementaciÃ³n

- Entorno de desarrollo: Google Colab
- Almacenamiento: Google Drive
- Lenguaje objetivo: EspaÃ±ol (ES)
- Framework de evaluaciÃ³n: Python + Jupyter Notebooks

## ğŸ”® PrÃ³ximos Pasos

1. Completar evaluaciÃ³n de modelos interrumpidos
2. Optimizar modelos seleccionados mediante fine-tuning
3. Implementar pipeline de producciÃ³n
4. Integrar modelo seleccionado en aplicaciÃ³n myMind

## ğŸ“„ Licencia

Este proyecto es parte del desarrollo acadÃ©mico en la Pontificia Universidad Javeriana para el proyecto myMind.

---

*Para mÃ¡s informaciÃ³n sobre la metodologÃ­a de evaluaciÃ³n y resultados detallados, consultar los notebooks incluidos en el repositorio.*
