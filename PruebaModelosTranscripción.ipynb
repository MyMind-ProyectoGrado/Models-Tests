{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1792o025gA6v"
      },
      "source": [
        "# **Evaluación de Modelos**\n",
        "---\n",
        "---\n",
        "##*Pontificia Universidad Javeriana*\n",
        "## *myMind*\n",
        "\n",
        "---\n",
        "\n",
        "**Juan José Gómez Arenas**\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "609sdAmkhuAg"
      },
      "source": [
        "# Instalación de dependencias generales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gvtc7pEhxVO",
        "outputId": "ee59352d-9ce5-43a6-c433-4441bbcbbcd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting jiwer\n",
            "  Downloading jiwer-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.1.8)\n",
            "Collecting rapidfuzz>=3.9.7 (from jiwer)\n",
            "  Downloading rapidfuzz-3.12.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Downloading jiwer-3.1.0-py3-none-any.whl (22 kB)\n",
            "Downloading rapidfuzz-3.12.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\n",
            "Successfully installed jiwer-3.1.0 rapidfuzz-3.12.2\n"
          ]
        }
      ],
      "source": [
        "%pip install jiwer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZbSmhytgK0e"
      },
      "source": [
        "# Obtención de datos\n",
        "Se obtienen los datos recolectados almacenados en drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-OPZO0TDN-l",
        "outputId": "cec406e1-79eb-47ee-b112-2141ee81475d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Montar Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOnngCK9cRiO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "# Definir rutas base en Google Drive\n",
        "BASE_DIR = \"/content/drive/MyDrive/Transcripcion\"\n",
        "AUDIO_DIR = os.path.join(BASE_DIR, \"Audios\")\n",
        "MANUAL_TRANSCRIPTS_DIR = os.path.join(BASE_DIR, \"Transcripciones_Manuales\")\n",
        "RESULTS_DIR = os.path.join(BASE_DIR, \"Resultados\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qtl1n461fWPi"
      },
      "outputs": [],
      "source": [
        "# Obtener lista de audios\n",
        "audio_files = glob.glob(os.path.join(AUDIO_DIR, \"*.wav\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TW94bINXfdwe",
        "outputId": "2f7475a8-0703-4507-963a-15eb5cb4e01b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/Transcripcion/Audios/A053.wav',\n",
              " '/content/drive/MyDrive/Transcripcion/Audios/A069.wav',\n",
              " '/content/drive/MyDrive/Transcripcion/Audios/A065.wav',\n",
              " '/content/drive/MyDrive/Transcripcion/Audios/A066.wav',\n",
              " '/content/drive/MyDrive/Transcripcion/Audios/A060.wav']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "audio_files[0:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ookEdF4feo0"
      },
      "source": [
        "# Metricas de evaluación\n",
        "Para esta sección se crearan funciones que permiten estructurar el procesamiento de los audios y la evaluación de las transcripciones. `get_manual_transcription()` recupera la transcripción manual correspondiente a cada audio. `calculate_metrics()` compara la transcripción generada por los modelos con la manual, calculando métricas clave:\n",
        "- *WER (Word Error Rate)* mide la tasa de errores de palabras\n",
        "- *WA (Word Accuracy)* mide la tasa de presición en terminos de palabras correctamente transcritas\n",
        "- *CER (Character Error Rate)* evalúa errores a nivel de caracteres\n",
        "- *WPM (Words Per Minute)* determina la velocidad de transcripción dividiendo el número de palabras por la duración del audio en minutos.\n",
        "\n",
        "Estas métricas permiten analizar la precisión y eficiencia de cada modelo, de manera que se pueda seleccionar el modelo que obtenga mejor rendimiento y que sea mas pertinente para la aplicación de myMind en terminos de ASR (Automatic Speech Recognition)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ei2t1mX4h9Et"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "\n",
        "def words_per_minute(text, audio_path):\n",
        "    \"\"\"Calcula la velocidad de transcripción en palabras por minuto (WPM) con duración real del audio.\"\"\"\n",
        "    word_count = len(text.split())\n",
        "    duration = librosa.get_duration(path=audio_path)  # Obtener duración en segundos\n",
        "    return word_count / (duration / 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSKi62tyhnK9"
      },
      "outputs": [],
      "source": [
        "# Función para calcular métricas\n",
        "from jiwer import wer, cer\n",
        "\n",
        "def calculate_metrics(reference, hypothesis, execution_time):\n",
        "    \"\"\"Calcula WER, CER, Levenshtein, WPM y el tiempo de ejecución.\"\"\"\n",
        "    word_error_rate = wer(reference, hypothesis)\n",
        "    return {\n",
        "        \"WER\": word_error_rate,\n",
        "        \"WA\": 1 - word_error_rate,\n",
        "        \"CER\": cer(reference, hypothesis),\n",
        "        \"WPM\": words_per_minute(hypothesis),\n",
        "        \"Execution Time (s)\": execution_time\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YWUyNpJlJSE"
      },
      "source": [
        "# Modelos\n",
        "A partir de la investigación realizada se pudieron identificar varios modelos relevantes para la transcripción de texto, de manera que a continuación se evalua el rendimiento de ellos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfgTokvmnf9L"
      },
      "source": [
        "## Whisper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJzZZMSolKB3"
      },
      "outputs": [],
      "source": [
        "# Instalar Whisper\n",
        "%%capture\n",
        "%pip install openai-whisper jiwer librosa\n",
        "%pip install torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eE0zEvxforW6",
        "outputId": "748f0ea2-8559-4d7c-deb3-a1324993e986"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Usando dispositivo: cpu\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████████████████████████████████| 72.1M/72.1M [00:01<00:00, 67.3MiB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Whisper tiny | Audio: A053.wav -> Execution Time: 10.90s | WPM: 125.75\n",
            "Whisper tiny | Audio: A069.wav -> Execution Time: 24.96s | WPM: 125.09\n",
            "Whisper tiny | Audio: A065.wav -> Execution Time: 3.74s | WPM: 139.35\n",
            "Whisper tiny | Audio: A066.wav -> Execution Time: 3.70s | WPM: 115.95\n",
            "Whisper tiny | Audio: A060.wav -> Execution Time: 6.82s | WPM: 155.03\n",
            "Whisper tiny | Audio: A062.wav -> Execution Time: 4.65s | WPM: 144.50\n",
            "Whisper tiny | Audio: A068.wav -> Execution Time: 3.24s | WPM: 139.77\n",
            "Whisper tiny | Audio: A061.wav -> Execution Time: 5.51s | WPM: 163.03\n",
            "Whisper tiny | Audio: A067.wav -> Execution Time: 4.08s | WPM: 114.93\n",
            "Whisper tiny | Audio: A064.wav -> Execution Time: 6.11s | WPM: 165.09\n",
            "Whisper tiny | Audio: A063.wav -> Execution Time: 4.30s | WPM: 140.53\n",
            "Whisper tiny | Audio: A056.wav -> Execution Time: 5.45s | WPM: 143.45\n",
            "Whisper tiny | Audio: A055.wav -> Execution Time: 4.55s | WPM: 123.84\n",
            "Whisper tiny | Audio: A001.wav -> Execution Time: 11.15s | WPM: 70.23\n",
            "Whisper tiny | Audio: A058.wav -> Execution Time: 4.82s | WPM: 162.52\n",
            "Whisper tiny | Audio: A057.wav -> Execution Time: 9.36s | WPM: 158.84\n",
            "Whisper tiny | Audio: A059.wav -> Execution Time: 13.17s | WPM: 138.47\n",
            "Whisper tiny | Audio: A032.wav -> Execution Time: 4.89s | WPM: 158.64\n",
            "Whisper tiny | Audio: A035.wav -> Execution Time: 4.47s | WPM: 93.71\n",
            "Whisper tiny | Audio: A031.wav -> Execution Time: 14.20s | WPM: 192.94\n",
            "Whisper tiny | Audio: A054.wav -> Execution Time: 3.91s | WPM: 130.44\n",
            "Whisper tiny | Audio: A029.wav -> Execution Time: 5.24s | WPM: 151.33\n",
            "Whisper tiny | Audio: A033.wav -> Execution Time: 4.44s | WPM: 174.19\n",
            "Whisper tiny | Audio: A030.wav -> Execution Time: 4.52s | WPM: 184.10\n",
            "Whisper tiny | Audio: A028.wav -> Execution Time: 5.86s | WPM: 172.87\n",
            "Whisper tiny | Audio: A026.wav -> Execution Time: 4.96s | WPM: 176.48\n",
            "Whisper tiny | Audio: A034.wav -> Execution Time: 13.88s | WPM: 91.96\n",
            "Whisper tiny | Audio: A019.wav -> Execution Time: 6.67s | WPM: 134.63\n",
            "Whisper tiny | Audio: A025.wav -> Execution Time: 3.85s | WPM: 163.25\n",
            "Whisper tiny | Audio: A022.wav -> Execution Time: 6.47s | WPM: 212.92\n",
            "Whisper tiny | Audio: A023.wav -> Execution Time: 5.49s | WPM: 171.27\n",
            "Whisper tiny | Audio: A027.wav -> Execution Time: 5.45s | WPM: 197.50\n",
            "Whisper tiny | Audio: A024.wav -> Execution Time: 4.34s | WPM: 158.10\n",
            "Whisper tiny | Audio: A020.wav -> Execution Time: 4.50s | WPM: 166.92\n",
            "Whisper tiny | Audio: A016.wav -> Execution Time: 8.57s | WPM: 154.45\n",
            "Whisper tiny | Audio: A014.wav -> Execution Time: 23.81s | WPM: 177.87\n",
            "Whisper tiny | Audio: A018.wav -> Execution Time: 11.03s | WPM: 189.86\n",
            "Whisper tiny | Audio: A021.wav -> Execution Time: 14.84s | WPM: 121.59\n",
            "Whisper tiny | Audio: A015.wav -> Execution Time: 7.53s | WPM: 141.46\n",
            "Whisper tiny | Audio: A010.wav -> Execution Time: 3.89s | WPM: 142.02\n",
            "Whisper tiny | Audio: A008.wav -> Execution Time: 2.84s | WPM: 167.16\n",
            "Whisper tiny | Audio: A009.wav -> Execution Time: 3.44s | WPM: 152.14\n",
            "Whisper tiny | Audio: A013.wav -> Execution Time: 8.70s | WPM: 171.29\n",
            "Whisper tiny | Audio: A012.wav -> Execution Time: 6.25s | WPM: 128.04\n",
            "Whisper tiny | Audio: A007.wav -> Execution Time: 3.27s | WPM: 177.05\n",
            "Whisper tiny | Audio: A017.wav -> Execution Time: 6.03s | WPM: 112.37\n",
            "Whisper tiny | Audio: A002.wav -> Execution Time: 2.80s | WPM: 108.67\n",
            "Whisper tiny | Audio: A039.wav -> Execution Time: 2.83s | WPM: 214.90\n",
            "Whisper tiny | Audio: A036.wav -> Execution Time: 2.61s | WPM: 183.87\n",
            "Whisper tiny | Audio: A037.wav -> Execution Time: 2.28s | WPM: 169.42\n",
            "Whisper tiny | Audio: A042.wav -> Execution Time: 5.55s | WPM: 161.63\n",
            "Whisper tiny | Audio: A003.wav -> Execution Time: 1.95s | WPM: 111.88\n",
            "Whisper tiny | Audio: A038.wav -> Execution Time: 1.90s | WPM: 191.23\n",
            "Whisper tiny | Audio: A005.wav -> Execution Time: 17.53s | WPM: 167.39\n",
            "Whisper tiny | Audio: A040.wav -> Execution Time: 5.43s | WPM: 147.52\n",
            "Whisper tiny | Audio: A004.wav -> Execution Time: 12.27s | WPM: 153.77\n",
            "Whisper tiny | Audio: A011.wav -> Execution Time: 6.48s | WPM: 166.18\n",
            "Whisper tiny | Audio: A046.wav -> Execution Time: 3.86s | WPM: 168.71\n",
            "Whisper tiny | Audio: A048.wav -> Execution Time: 2.82s | WPM: 140.02\n",
            "Whisper tiny | Audio: A006.wav -> Execution Time: 28.06s | WPM: 140.66\n",
            "Whisper tiny | Audio: A041.wav -> Execution Time: 4.55s | WPM: 128.76\n",
            "Whisper tiny | Audio: A045.wav -> Execution Time: 3.61s | WPM: 154.68\n",
            "Whisper tiny | Audio: A047.wav -> Execution Time: 4.28s | WPM: 127.57\n",
            "Whisper tiny | Audio: A044.wav -> Execution Time: 4.53s | WPM: 108.18\n",
            "Whisper tiny | Audio: A043.wav -> Execution Time: 11.17s | WPM: 173.99\n",
            "Whisper tiny | Audio: A049.wav -> Execution Time: 3.94s | WPM: 137.48\n",
            "Whisper tiny | Audio: A052.wav -> Execution Time: 2.65s | WPM: 137.82\n",
            "Whisper tiny | Audio: A050.wav -> Execution Time: 3.30s | WPM: 170.76\n",
            "Whisper tiny | Audio: A051.wav -> Execution Time: 4.23s | WPM: 184.40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 461M/461M [00:10<00:00, 45.6MiB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Whisper small | Audio: A053.wav -> Execution Time: 25.40s | WPM: 117.89\n",
            "Whisper small | Audio: A069.wav -> Execution Time: 30.02s | WPM: 119.88\n",
            "Whisper small | Audio: A065.wav -> Execution Time: 15.96s | WPM: 134.54\n",
            "Whisper small | Audio: A066.wav -> Execution Time: 25.70s | WPM: 112.39\n",
            "Whisper small | Audio: A060.wav -> Execution Time: 46.59s | WPM: 155.03\n",
            "Whisper small | Audio: A062.wav -> Execution Time: 30.75s | WPM: 146.31\n",
            "Whisper small | Audio: A068.wav -> Execution Time: 14.55s | WPM: 134.28\n",
            "Whisper small | Audio: A061.wav -> Execution Time: 28.47s | WPM: 159.67\n",
            "Whisper small | Audio: A067.wav -> Execution Time: 27.57s | WPM: 122.69\n",
            "Whisper small | Audio: A064.wav -> Execution Time: 31.30s | WPM: 158.35\n",
            "Whisper small | Audio: A063.wav -> Execution Time: 29.13s | WPM: 138.90\n",
            "Whisper small | Audio: A056.wav -> Execution Time: 28.85s | WPM: 138.87\n",
            "Whisper small | Audio: A055.wav -> Execution Time: 28.06s | WPM: 119.42\n",
            "Whisper small | Audio: A001.wav -> Execution Time: 63.45s | WPM: 91.68\n",
            "Whisper small | Audio: A058.wav -> Execution Time: 29.47s | WPM: 163.96\n",
            "Whisper small | Audio: A057.wav -> Execution Time: 33.55s | WPM: 156.30\n",
            "Whisper small | Audio: A059.wav -> Execution Time: 30.54s | WPM: 130.18\n",
            "Whisper small | Audio: A032.wav -> Execution Time: 28.82s | WPM: 151.67\n",
            "Whisper small | Audio: A035.wav -> Execution Time: 22.67s | WPM: 87.85\n",
            "Whisper small | Audio: A031.wav -> Execution Time: 33.84s | WPM: 206.44\n",
            "Whisper small | Audio: A054.wav -> Execution Time: 26.75s | WPM: 123.39\n",
            "Whisper small | Audio: A029.wav -> Execution Time: 29.94s | WPM: 172.14\n",
            "Whisper small | Audio: A033.wav -> Execution Time: 26.38s | WPM: 144.54\n",
            "Whisper small | Audio: A030.wav -> Execution Time: 21.15s | WPM: 161.85\n",
            "Whisper small | Audio: A028.wav -> Execution Time: 30.47s | WPM: 178.45\n",
            "Whisper small | Audio: A026.wav -> Execution Time: 30.11s | WPM: 166.10\n",
            "Whisper small | Audio: A034.wav -> Execution Time: 82.08s | WPM: 99.78\n",
            "Whisper small | Audio: A019.wav -> Execution Time: 32.22s | WPM: 130.79\n",
            "Whisper small | Audio: A025.wav -> Execution Time: 27.12s | WPM: 157.28\n",
            "Whisper small | Audio: A022.wav -> Execution Time: 31.83s | WPM: 226.72\n",
            "Whisper small | Audio: A023.wav -> Execution Time: 32.91s | WPM: 155.83\n",
            "Whisper small | Audio: A027.wav -> Execution Time: 29.54s | WPM: 189.98\n",
            "Whisper small | Audio: A024.wav -> Execution Time: 28.49s | WPM: 159.94\n",
            "Whisper small | Audio: A020.wav -> Execution Time: 27.90s | WPM: 164.97\n",
            "Whisper small | Audio: A016.wav -> Execution Time: 36.82s | WPM: 141.75\n",
            "Whisper small | Audio: A014.wav -> Execution Time: 37.68s | WPM: 160.98\n",
            "Whisper small | Audio: A018.wav -> Execution Time: 52.96s | WPM: 177.33\n",
            "Whisper small | Audio: A021.wav -> Execution Time: 24.21s | WPM: 94.14\n",
            "Whisper small | Audio: A015.wav -> Execution Time: 49.47s | WPM: 147.56\n",
            "Whisper small | Audio: A010.wav -> Execution Time: 17.53s | WPM: 153.12\n",
            "Whisper small | Audio: A008.wav -> Execution Time: 19.30s | WPM: 172.82\n",
            "Whisper small | Audio: A009.wav -> Execution Time: 17.68s | WPM: 161.09\n",
            "Whisper small | Audio: A013.wav -> Execution Time: 46.44s | WPM: 158.27\n",
            "Whisper small | Audio: A012.wav -> Execution Time: 32.53s | WPM: 130.39\n",
            "Whisper small | Audio: A007.wav -> Execution Time: 14.71s | WPM: 173.89\n",
            "Whisper small | Audio: A017.wav -> Execution Time: 40.67s | WPM: 113.36\n",
            "Whisper small | Audio: A002.wav -> Execution Time: 13.83s | WPM: 106.02\n",
            "Whisper small | Audio: A039.wav -> Execution Time: 15.84s | WPM: 200.08\n",
            "Whisper small | Audio: A036.wav -> Execution Time: 15.26s | WPM: 151.04\n",
            "Whisper small | Audio: A037.wav -> Execution Time: 14.80s | WPM: 172.87\n",
            "Whisper small | Audio: A042.wav -> Execution Time: 28.26s | WPM: 161.63\n",
            "Whisper small | Audio: A003.wav -> Execution Time: 13.53s | WPM: 108.49\n",
            "Whisper small | Audio: A038.wav -> Execution Time: 12.89s | WPM: 191.23\n",
            "Whisper small | Audio: A005.wav -> Execution Time: 45.49s | WPM: 148.32\n",
            "Whisper small | Audio: A040.wav -> Execution Time: 30.17s | WPM: 122.44\n",
            "Whisper small | Audio: A004.wav -> Execution Time: 68.04s | WPM: 154.46\n",
            "Whisper small | Audio: A011.wav -> Execution Time: 36.89s | WPM: 155.95\n",
            "Whisper small | Audio: A046.wav -> Execution Time: 17.00s | WPM: 160.42\n",
            "Whisper small | Audio: A048.wav -> Execution Time: 16.94s | WPM: 131.79\n",
            "Whisper small | Audio: A006.wav -> Execution Time: 85.75s | WPM: 160.06\n",
            "Whisper small | Audio: A041.wav -> Execution Time: 27.54s | WPM: 136.91\n",
            "Whisper small | Audio: A045.wav -> Execution Time: 16.95s | WPM: 157.26\n",
            "Whisper small | Audio: A047.wav -> Execution Time: 28.39s | WPM: 136.55\n",
            "Whisper small | Audio: A044.wav -> Execution Time: 24.42s | WPM: 109.68\n",
            "Whisper small | Audio: A043.wav -> Execution Time: 27.01s | WPM: 136.47\n",
            "Whisper small | Audio: A049.wav -> Execution Time: 19.19s | WPM: 142.22\n",
            "Whisper small | Audio: A052.wav -> Execution Time: 16.79s | WPM: 150.82\n",
            "Whisper small | Audio: A050.wav -> Execution Time: 18.75s | WPM: 150.67\n",
            "Whisper small | Audio: A051.wav -> Execution Time: 16.39s | WPM: 157.63\n",
            "Skipping A053.wav, transcription already exists for medium.\n",
            "Skipping A069.wav, transcription already exists for medium.\n",
            "Skipping A065.wav, transcription already exists for medium.\n",
            "Skipping A066.wav, transcription already exists for medium.\n",
            "Skipping A060.wav, transcription already exists for medium.\n",
            "Skipping A062.wav, transcription already exists for medium.\n",
            "Skipping A068.wav, transcription already exists for medium.\n",
            "Skipping A061.wav, transcription already exists for medium.\n",
            "Skipping A067.wav, transcription already exists for medium.\n",
            "Skipping A064.wav, transcription already exists for medium.\n",
            "Skipping A063.wav, transcription already exists for medium.\n",
            "Skipping A056.wav, transcription already exists for medium.\n",
            "Skipping A055.wav, transcription already exists for medium.\n",
            "Skipping A001.wav, transcription already exists for medium.\n",
            "Skipping A058.wav, transcription already exists for medium.\n",
            "Skipping A057.wav, transcription already exists for medium.\n",
            "Skipping A059.wav, transcription already exists for medium.\n",
            "Skipping A032.wav, transcription already exists for medium.\n",
            "Skipping A035.wav, transcription already exists for medium.\n",
            "Skipping A031.wav, transcription already exists for medium.\n",
            "Skipping A054.wav, transcription already exists for medium.\n",
            "Skipping A029.wav, transcription already exists for medium.\n",
            "Skipping A033.wav, transcription already exists for medium.\n",
            "Skipping A030.wav, transcription already exists for medium.\n",
            "Skipping A028.wav, transcription already exists for medium.\n",
            "Skipping A026.wav, transcription already exists for medium.\n",
            "Skipping A034.wav, transcription already exists for medium.\n",
            "Skipping A019.wav, transcription already exists for medium.\n",
            "Skipping A025.wav, transcription already exists for medium.\n",
            "Skipping A022.wav, transcription already exists for medium.\n",
            "Skipping A023.wav, transcription already exists for medium.\n",
            "Skipping A027.wav, transcription already exists for medium.\n",
            "Skipping A024.wav, transcription already exists for medium.\n",
            "Skipping A020.wav, transcription already exists for medium.\n",
            "Skipping A016.wav, transcription already exists for medium.\n",
            "Skipping A014.wav, transcription already exists for medium.\n",
            "Skipping A018.wav, transcription already exists for medium.\n",
            "Skipping A021.wav, transcription already exists for medium.\n",
            "Skipping A015.wav, transcription already exists for medium.\n",
            "Skipping A010.wav, transcription already exists for medium.\n",
            "Skipping A008.wav, transcription already exists for medium.\n",
            "Skipping A009.wav, transcription already exists for medium.\n",
            "Skipping A013.wav, transcription already exists for medium.\n",
            "Skipping A012.wav, transcription already exists for medium.\n",
            "Skipping A007.wav, transcription already exists for medium.\n",
            "Skipping A017.wav, transcription already exists for medium.\n",
            "Skipping A002.wav, transcription already exists for medium.\n",
            "Skipping A039.wav, transcription already exists for medium.\n",
            "Skipping A036.wav, transcription already exists for medium.\n",
            "Skipping A037.wav, transcription already exists for medium.\n",
            "Skipping A042.wav, transcription already exists for medium.\n",
            "Skipping A003.wav, transcription already exists for medium.\n",
            "Skipping A038.wav, transcription already exists for medium.\n",
            "Skipping A005.wav, transcription already exists for medium.\n",
            "Skipping A040.wav, transcription already exists for medium.\n",
            "Skipping A004.wav, transcription already exists for medium.\n",
            "Skipping A011.wav, transcription already exists for medium.\n",
            "Skipping A046.wav, transcription already exists for medium.\n",
            "Skipping A048.wav, transcription already exists for medium.\n",
            "Skipping A006.wav, transcription already exists for medium.\n",
            "Skipping A041.wav, transcription already exists for medium.\n",
            "Skipping A045.wav, transcription already exists for medium.\n",
            "Skipping A047.wav, transcription already exists for medium.\n",
            "Skipping A044.wav, transcription already exists for medium.\n",
            "Skipping A043.wav, transcription already exists for medium.\n",
            "Skipping A049.wav, transcription already exists for medium.\n",
            "Skipping A052.wav, transcription already exists for medium.\n",
            "Skipping A050.wav, transcription already exists for medium.\n",
            "Skipping A051.wav, transcription already exists for medium.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████████████████████████████████| 2.88G/2.88G [00:53<00:00, 57.3MiB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Whisper large | Audio: A053.wav -> Execution Time: 151.51s | WPM: 129.67\n"
          ]
        }
      ],
      "source": [
        "import whisper\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "\n",
        "# Directorios\n",
        "AUDIO_DIR = \"/content/drive/MyDrive/Transcripcion/Audios\"\n",
        "RESULTS_DIR = \"/content/drive/MyDrive/Transcripcion/Resultados\"\n",
        "\n",
        "# Modelos a probar\n",
        "WHISPER_SIZES = [\"tiny\", \"small\", \"medium\", \"large\"]\n",
        "\n",
        "# Configuración de dispositivo\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Usando dispositivo: {DEVICE}\")\n",
        "\n",
        "# Función de transcripción con Whisper\n",
        "def transcribe_whisper(model_size, audio_path):\n",
        "    \"\"\"Ejecuta transcripción con Whisper y mide tiempo de ejecución.\"\"\"\n",
        "    model = whisper.load_model(model_size, device=DEVICE)\n",
        "    start_time = time.time()\n",
        "    result = model.transcribe(audio_path, language=\"es\")\n",
        "    execution_time = time.time() - start_time\n",
        "    return result[\"text\"], execution_time\n",
        "\n",
        "# Procesar audios con Whisper\n",
        "for model_size in WHISPER_SIZES:\n",
        "    model_results_dir = os.path.join(RESULTS_DIR, f\"Whisper_{model_size}\")\n",
        "    os.makedirs(model_results_dir, exist_ok=True)\n",
        "\n",
        "    for audio_file in os.listdir(AUDIO_DIR):\n",
        "        if audio_file.endswith(\".wav\"):\n",
        "            audio_path = os.path.join(AUDIO_DIR, audio_file)\n",
        "            transcript_file = os.path.join(model_results_dir, audio_file.replace(\".wav\", \"_T.txt\"))\n",
        "            metrics_file = os.path.join(model_results_dir, audio_file.replace(\".wav\", \"_Metrics.txt\"))\n",
        "\n",
        "            # Verificación antes de transcribir\n",
        "            if os.path.exists(transcript_file):\n",
        "                print(f\"Skipping {audio_file}, transcription already exists for {model_size}.\")\n",
        "                continue\n",
        "\n",
        "            # Ejecutar transcripción\n",
        "            hypothesis, exec_time = transcribe_whisper(model_size, audio_path)\n",
        "\n",
        "            # Guardar transcripción\n",
        "            with open(transcript_file, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(hypothesis)\n",
        "\n",
        "            # Calcular WPM\n",
        "            wpm = words_per_minute(hypothesis, audio_path)\n",
        "\n",
        "            # Guardar métricas (Tiempo y WPM)\n",
        "            with open(metrics_file, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(f\"Execution Time (s): {exec_time:.2f}\\n\")\n",
        "                f.write(f\"WPM: {wpm:.2f}\\n\")\n",
        "\n",
        "            print(f\"Whisper {model_size} | Audio: {audio_file} -> Execution Time: {exec_time:.2f}s | WPM: {wpm:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDNwul46RN-A"
      },
      "source": [
        "Al realizar la prueba con el modelo large, el entorno fallo, por la siguiente razon:\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "Tomando esto en consideración y teniendo en cuenta que el entorno tiene una capacidad de mas de 12 GB de RAM, además de las limitaciones de los recursos con los que cuenta el equipo, se decide omitir la prueba de este modelo ya que no cumple con las necesidades que tiene la aplicación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhbXIbCYv2SX"
      },
      "source": [
        "## Whisper X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zb1QJLipv4qu"
      },
      "outputs": [],
      "source": [
        "!pip install -q whisperx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRQmXIm9v9ua"
      },
      "outputs": [],
      "source": [
        "import whisperx\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "\n",
        "# Modelos a probar\n",
        "WHISPERX_SIZES = [\"medium\", \"large\"]\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Usando dispositivo: {DEVICE}\")\n",
        "\n",
        "# Procesar audios con WhisperX\n",
        "for model_size in WHISPERX_SIZES:\n",
        "    model_results_dir = os.path.join(RESULTS_DIR, f\"WhisperX_{model_size}\")\n",
        "    os.makedirs(model_results_dir, exist_ok=True)\n",
        "\n",
        "    # Cargar modelo de WhisperX\n",
        "    model = whisperx.load_model(model_size, DEVICE)\n",
        "\n",
        "    for audio_file in os.listdir(AUDIO_DIR):\n",
        "        if audio_file.endswith(\".wav\"):\n",
        "            audio_path = os.path.join(AUDIO_DIR, audio_file)\n",
        "            transcript_file = os.path.join(model_results_dir, audio_file.replace(\".wav\", \"_T.txt\"))\n",
        "\n",
        "            # Transcripción\n",
        "            start_time = time.time()\n",
        "            result = model.transcribe(audio_path, language=\"es\")\n",
        "            execution_time = time.time() - start_time\n",
        "            transcript = result[\"text\"]\n",
        "\n",
        "            # Guardar transcripción\n",
        "            with open(transcript_file, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(transcript)\n",
        "\n",
        "            # Calcular WPM\n",
        "            wpm = words_per_minute(transcript, audio_path)\n",
        "\n",
        "            # Guardar métricas básicas (WPM y tiempo de ejecución)\n",
        "            metrics_file = os.path.join(model_results_dir, audio_file.replace(\".wav\", \"_Metrics.txt\"))\n",
        "            with open(metrics_file, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(f\"Execution Time (s): {execution_time:.2f}\\n\")\n",
        "                f.write(f\"WPM: {wpm:.2f}\\n\")\n",
        "\n",
        "            print(f\"WhisperX {model_size} | Audio: {audio_file} -> Execution Time: {execution_time:.2f}s, WPM: {wpm:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bj5ETQxDgx3V"
      },
      "source": [
        "## Wav2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azUCfDSghUGx"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install transformers torchaudio librosa\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "bf95f0813ec24383a64f51de7e1bcb3b",
            "d5342f87343d4ccfa8c820a5b63156b3",
            "72ea22fa475740a5b0beace38649bf5d",
            "1528432236f04f74b83c3ed6b166b279",
            "667ab26e7846467f872974ea9d42006b",
            "45f8289ba7c347508a2b56aaf9096c36",
            "f8eb500ab5274c008172b38e1d82a63f",
            "557d8ed4847e4e1888438b86af4f9da7",
            "693f5302799846ec8858052ea3cb9276",
            "98ec7a46035945c48054ffc309985527",
            "cad32b63421b412a9cb3769802797b38",
            "33da0991344944acab9b2159bdc88aff",
            "194bd6d13ef84d21a7bf59287400865b",
            "03798385c704408a910d6d41adc3abfb",
            "aa3d6e0b36d941fba5956774a0691fea",
            "03991ffcd8bd43c0bcb3af0fae337ef6",
            "5a1bdeeeabdf437bb224e56b39516e5a",
            "bb6fc18ea0d94262910caad9b7be4290",
            "86f22ad4d0244d70bddf66de773a2439",
            "30dfd16c6c3a45d1aa056e56b747d9d3",
            "47c9a29a824c4d1fae06f6f23d3ce4d4",
            "7f28eff8b68c4ca1af530b66c61995eb",
            "a9394fbcfd7e41b89013e3be1e3283e6",
            "3911059689f84af1ab0bc3ecf78a0060",
            "80b335ad74a944d899d4c60a1f8349a2",
            "6e881b47ee9a40088c83247cf0383c28",
            "f3e12b8082bb40afac5cd499e4bcfb9c",
            "482f613250104e0cbfc400576a12a784",
            "b156b2fd61a34186a72ba599d34b7b48",
            "c80069d5cf8245f9b93337050bb61bc1",
            "96d74a9710f64a6ca9ca7fc9699f7071",
            "592566b0b3b64a618adbdb9af05fabdb",
            "14538a2040fc4a3a9b1f094607b6b996",
            "08e5bde1eac146f7bc529dc2c38aa900",
            "e4cf93f723564111b07399e6ea70e40b",
            "228ebead60a24a28b92703d0443cfdc4",
            "97fc1044d51a44a299c634a8a2997c61",
            "6b1358a1191849f49aebad0201923634",
            "05beee139a96471eb791afbcd0e2c297",
            "6bdf001617ab4aa496566aabd3143f02",
            "de4b539ca9274aea9c31de4feb37af0b",
            "f2b80bf9c9a347858dc244986f31fccc",
            "94869d5629e4424aab5e6830c03e4647",
            "97858d6e146e42c7be2d908b96e61304",
            "2f5f22ab784f42a7b2fab8533c0c61fb",
            "9d0a698cd743495e8ec2b120954e4cc6",
            "c87ea1624dea40d1973a2fcfae79b14b",
            "ea6dc050287b4699a16a7ac1c3364aaa",
            "f8be9eb33c724915b64d15989f2e30e4",
            "818d38e5af6445e2bfcc10ba7b41bccc",
            "2aee8d9ec8d64748bddae7dca2c3de0b",
            "59b5471b57674d9a9ea17401ebd4d94e",
            "e5c42b4779fc48cd92bf8aed0af18d44",
            "e72fba52b45846709c95e210d5f8b5ca",
            "41ceb22e40c24b7a80ef21685ff5fa5e",
            "9ebe815100df4495b1f35ec1aa3e1879",
            "1f7ed628fd3948409b560902a99cfa0b",
            "c99792be442b4e22a56f4ffefb4bfcd5",
            "d0e67cbe3454421c92ac8d5ae4223d19",
            "ff45379e0e9d4ddaa966bdd18cb976a6",
            "e5a0a98be17a4d63b0f8f9d8deaa3dad",
            "9fcf7eb415a24345b3b9c7add1a1f8d0",
            "e6f6777bba914442acd2f549766e2370",
            "0e5ccb39e7e64a8aafc7f4d15814720f",
            "7710df23feed4dbda6fcc62721d03979",
            "74856582a4034e7a9257d050aa51f632"
          ]
        },
        "id": "YxgG6W0vhkkc",
        "outputId": "f341b471-3051-4344-d971-f654b270226d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Usando dispositivo: cpu\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf95f0813ec24383a64f51de7e1bcb3b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/159 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "33da0991344944acab9b2159bdc88aff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/163 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a9394fbcfd7e41b89013e3be1e3283e6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.60k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "08e5bde1eac146f7bc529dc2c38aa900",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/291 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2f5f22ab784f42a7b2fab8533c0c61fb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ebe815100df4495b1f35ec1aa3e1879",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/378M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wav2Vec base | Audio: A053.wav -> Execution Time: 10.57s | WPM: 312.25\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wav2Vec base | Audio: A069.wav -> Execution Time: 12.29s | WPM: 283.13\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wav2Vec base | Audio: A065.wav -> Execution Time: 17.36s | WPM: 186.64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wav2Vec base | Audio: A066.wav -> Execution Time: 12.36s | WPM: 325.19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wav2Vec base | Audio: A060.wav -> Execution Time: 24.49s | WPM: 191.11\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wav2Vec base | Audio: A062.wav -> Execution Time: 11.55s | WPM: 233.69\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-bd6bdc9256cb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;31m# Ejecutar transcripción\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mhypothesis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexec_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranscribe_wav2vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# Guardar transcripción\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-bd6bdc9256cb>\u001b[0m in \u001b[0;36mtranscribe_wav2vec\u001b[0;34m(model_name, audio_path)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mpredicted_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mtranscription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/wav2vec2/modeling_wav2vec2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_values, attention_mask, output_attentions, output_hidden_states, return_dict, labels)\u001b[0m\n\u001b[1;32m   2225\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Label values must be <= vocab_size: {self.config.vocab_size}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2227\u001b[0;31m         outputs = self.wav2vec2(\n\u001b[0m\u001b[1;32m   2228\u001b[0m             \u001b[0minput_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2229\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/wav2vec2/modeling_wav2vec2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_values, attention_mask, mask_time_indices, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1806\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1808\u001b[0;31m         \u001b[0mextract_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1809\u001b[0m         \u001b[0mextract_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/wav2vec2/modeling_wav2vec2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_values)\u001b[0m\n\u001b[1;32m    461\u001b[0m                 )\n\u001b[1;32m    462\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m                 \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/wav2vec2/modeling_wav2vec2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    368\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m             )\n\u001b[0;32m--> 370\u001b[0;31m         return F.conv1d(\n\u001b[0m\u001b[1;32m    371\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torchaudio\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
        "import torch\n",
        "import os\n",
        "import time\n",
        "\n",
        "#  Modelos a probar\n",
        "WAV2VEC_MODELS = {\n",
        "    \"base\": \"facebook/wav2vec2-base-960h\",\n",
        "    \"medium\": \"facebook/wav2vec2-large-xlsr-53-spanish\",\n",
        "    \"large\": \"facebook/wav2vec2-large-960h\"\n",
        "}\n",
        "\n",
        "#  Configuración de dispositivo\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Usando dispositivo: {DEVICE}\")\n",
        "\n",
        "#  Función para transcribir audio\n",
        "def transcribe_wav2vec(model_name, audio_path):\n",
        "    \"\"\"Ejecuta transcripción con Wav2Vec 2.0 y mide tiempo de ejecución.\"\"\"\n",
        "    processor = Wav2Vec2Processor.from_pretrained(model_name)\n",
        "    model = Wav2Vec2ForCTC.from_pretrained(model_name).to(DEVICE)\n",
        "\n",
        "    # Cargar audio\n",
        "    waveform, sample_rate = torchaudio.load(audio_path)\n",
        "    waveform = waveform.squeeze()\n",
        "\n",
        "    #  Convertir a 16kHz si es necesario\n",
        "    if sample_rate != 16000:\n",
        "        transform = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n",
        "        waveform = transform(waveform)\n",
        "\n",
        "    # Preparar entrada\n",
        "    input_values = processor(waveform, sampling_rate=16000, return_tensors=\"pt\").input_values.to(DEVICE)\n",
        "\n",
        "    #  Transcribir\n",
        "    start_time = time.time()\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_values).logits\n",
        "    predicted_ids = torch.argmax(logits, dim=-1)\n",
        "    transcription = processor.batch_decode(predicted_ids)[0]\n",
        "    execution_time = time.time() - start_time\n",
        "\n",
        "    return transcription, execution_time\n",
        "\n",
        "# Procesar audios con Wav2Vec 2.0\n",
        "for model_size, model_name in WAV2VEC_MODELS.items():\n",
        "    model_results_dir = os.path.join(RESULTS_DIR, f\"Wav2Vec_{model_size}\")\n",
        "    os.makedirs(model_results_dir, exist_ok=True)\n",
        "\n",
        "    for audio_file in os.listdir(AUDIO_DIR):\n",
        "        if audio_file.endswith(\".wav\"):\n",
        "            audio_path = os.path.join(AUDIO_DIR, audio_file)\n",
        "            transcript_file = os.path.join(model_results_dir, audio_file.replace(\".wav\", \"_T.txt\"))\n",
        "            metrics_file = os.path.join(model_results_dir, audio_file.replace(\".wav\", \"_Metrics.txt\"))\n",
        "\n",
        "            # Verificación antes de transcribir\n",
        "            if os.path.exists(transcript_file):\n",
        "                print(f\"Skipping {audio_file}, transcription already exists for {model_size}.\")\n",
        "                continue\n",
        "\n",
        "            # Ejecutar transcripción\n",
        "            hypothesis, exec_time = transcribe_wav2vec(model_name, audio_path)\n",
        "\n",
        "            # Guardar transcripción\n",
        "            with open(transcript_file, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(hypothesis)\n",
        "\n",
        "            # Calcular WPM (si quieres, agrégalo)\n",
        "            wpm = len(hypothesis.split()) / (exec_time / 60)\n",
        "\n",
        "            #  Guardar métricas\n",
        "            with open(metrics_file, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(f\"Execution Time (s): {exec_time:.2f}\\n\")\n",
        "                f.write(f\"WPM: {wpm:.2f}\\n\")\n",
        "\n",
        "            print(f\"Wav2Vec {model_size} | Audio: {audio_file} -> Execution Time: {exec_time:.2f}s | WPM: {wpm:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWz4TnriGhLu"
      },
      "source": [
        "##SpeechBrain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9xQyD9EGjNx"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install speechbrain transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nV2tWEeaGoEw",
        "outputId": "4a53d00b-c3d4-45df-e6b0-4fe258755253"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SpeechBrain | Audio: A009.wav -> Execution Time: 28.09s | WPM: 104.67\n",
            "SpeechBrain | Audio: A008.wav -> Execution Time: 21.87s | WPM: 109.72\n",
            "SpeechBrain | Audio: A007.wav -> Execution Time: 18.91s | WPM: 123.74\n",
            "SpeechBrain | Audio: A006.wav -> Execution Time: 186.50s | WPM: 46.01\n",
            "SpeechBrain | Audio: A005.wav -> Execution Time: 72.63s | WPM: 76.83\n",
            "SpeechBrain | Audio: A004.wav -> Execution Time: 130.28s | WPM: 38.68\n",
            "SpeechBrain | Audio: A003.wav -> Execution Time: 19.05s | WPM: 85.02\n",
            "SpeechBrain | Audio: A002.wav -> Execution Time: 23.34s | WPM: 95.11\n",
            "SpeechBrain | Audio: A001.wav -> Execution Time: 34.25s | WPM: 66.58\n",
            "SpeechBrain | Audio: A038.wav -> Execution Time: 10.06s | WPM: 172.98\n",
            "SpeechBrain | Audio: A018.wav -> Execution Time: 83.74s | WPM: 80.25\n",
            "SpeechBrain | Audio: A017.wav -> Execution Time: 82.01s | WPM: 76.82\n",
            "SpeechBrain | Audio: A016.wav -> Execution Time: 74.23s | WPM: 90.53\n",
            "SpeechBrain | Audio: A015.wav -> Execution Time: 75.86s | WPM: 83.84\n",
            "SpeechBrain | Audio: A014.wav -> Execution Time: 67.54s | WPM: 56.86\n",
            "SpeechBrain | Audio: A013.wav -> Execution Time: 77.72s | WPM: 84.93\n",
            "SpeechBrain | Audio: A012.wav -> Execution Time: 62.72s | WPM: 91.84\n",
            "SpeechBrain | Audio: A011.wav -> Execution Time: 56.91s | WPM: 97.00\n",
            "SpeechBrain | Audio: A010.wav -> Execution Time: 29.36s | WPM: 132.81\n",
            "SpeechBrain | Audio: A039.wav -> Execution Time: 16.30s | WPM: 136.16\n",
            "SpeechBrain | Audio: A037.wav -> Execution Time: 17.43s | WPM: 161.81\n",
            "SpeechBrain | Audio: A036.wav -> Execution Time: 18.46s | WPM: 156.03\n",
            "SpeechBrain | Audio: A035.wav -> Execution Time: 35.01s | WPM: 82.27\n",
            "SpeechBrain | Audio: A034.wav -> Execution Time: 84.91s | WPM: 53.00\n",
            "SpeechBrain | Audio: A033.wav -> Execution Time: 37.24s | WPM: 95.05\n",
            "SpeechBrain | Audio: A032.wav -> Execution Time: 38.55s | WPM: 101.16\n",
            "SpeechBrain | Audio: A031.wav -> Execution Time: 35.62s | WPM: 107.81\n",
            "SpeechBrain | Audio: A030.wav -> Execution Time: 32.95s | WPM: 107.43\n",
            "SpeechBrain | Audio: A029.wav -> Execution Time: 34.64s | WPM: 90.06\n",
            "SpeechBrain | Audio: A028.wav -> Execution Time: 35.48s | WPM: 103.16\n",
            "SpeechBrain | Audio: A027.wav -> Execution Time: 35.90s | WPM: 132.05\n",
            "SpeechBrain | Audio: A026.wav -> Execution Time: 38.30s | WPM: 120.64\n",
            "SpeechBrain | Audio: A025.wav -> Execution Time: 33.86s | WPM: 127.58\n",
            "SpeechBrain | Audio: A024.wav -> Execution Time: 35.70s | WPM: 102.52\n",
            "SpeechBrain | Audio: A023.wav -> Execution Time: 50.57s | WPM: 105.59\n",
            "SpeechBrain | Audio: A022.wav -> Execution Time: 33.83s | WPM: 159.61\n",
            "SpeechBrain | Audio: A021.wav -> Execution Time: 33.03s | WPM: 69.03\n",
            "SpeechBrain | Audio: A020.wav -> Execution Time: 33.79s | WPM: 110.11\n",
            "SpeechBrain | Audio: A019.wav -> Execution Time: 56.73s | WPM: 92.01\n",
            "SpeechBrain | Audio: A059.wav -> Execution Time: 66.62s | WPM: 88.26\n",
            "SpeechBrain | Audio: A058.wav -> Execution Time: 50.44s | WPM: 122.53\n",
            "SpeechBrain | Audio: A057.wav -> Execution Time: 57.41s | WPM: 98.25\n",
            "SpeechBrain | Audio: A056.wav -> Execution Time: 45.57s | WPM: 101.39\n",
            "SpeechBrain | Audio: A055.wav -> Execution Time: 47.25s | WPM: 91.42\n",
            "SpeechBrain | Audio: A054.wav -> Execution Time: 38.60s | WPM: 102.58\n",
            "SpeechBrain | Audio: A053.wav -> Execution Time: 33.70s | WPM: 89.03\n",
            "SpeechBrain | Audio: A052.wav -> Execution Time: 23.13s | WPM: 142.69\n",
            "SpeechBrain | Audio: A051.wav -> Execution Time: 21.67s | WPM: 135.65\n",
            "SpeechBrain | Audio: A050.wav -> Execution Time: 24.55s | WPM: 124.63\n",
            "SpeechBrain | Audio: A049.wav -> Execution Time: 26.40s | WPM: 129.53\n",
            "SpeechBrain | Audio: A048.wav -> Execution Time: 23.57s | WPM: 127.27\n",
            "SpeechBrain | Audio: A047.wav -> Execution Time: 36.76s | WPM: 115.88\n",
            "SpeechBrain | Audio: A046.wav -> Execution Time: 23.40s | WPM: 138.45\n",
            "SpeechBrain | Audio: A045.wav -> Execution Time: 23.49s | WPM: 150.72\n",
            "SpeechBrain | Audio: A044.wav -> Execution Time: 46.43s | WPM: 86.59\n",
            "SpeechBrain | Audio: A043.wav -> Execution Time: 39.11s | WPM: 110.46\n",
            "SpeechBrain | Audio: A042.wav -> Execution Time: 42.76s | WPM: 123.49\n",
            "SpeechBrain | Audio: A041.wav -> Execution Time: 42.01s | WPM: 92.84\n",
            "SpeechBrain | Audio: A040.wav -> Execution Time: 47.28s | WPM: 78.68\n",
            "SpeechBrain | Audio: A069.wav -> Execution Time: 39.53s | WPM: 92.60\n",
            "SpeechBrain | Audio: A065.wav -> Execution Time: 25.21s | WPM: 114.23\n",
            "SpeechBrain | Audio: A066.wav -> Execution Time: 38.23s | WPM: 86.32\n",
            "SpeechBrain | Audio: A060.wav -> Execution Time: 68.88s | WPM: 81.89\n",
            "SpeechBrain | Audio: A062.wav -> Execution Time: 40.71s | WPM: 98.74\n",
            "SpeechBrain | Audio: A068.wav -> Execution Time: 23.67s | WPM: 96.34\n",
            "SpeechBrain | Audio: A061.wav -> Execution Time: 40.30s | WPM: 89.32\n",
            "SpeechBrain | Audio: A067.wav -> Execution Time: 44.61s | WPM: 82.04\n",
            "SpeechBrain | Audio: A064.wav -> Execution Time: 39.49s | WPM: 104.82\n",
            "SpeechBrain | Audio: A063.wav -> Execution Time: 42.04s | WPM: 112.74\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "from speechbrain.inference.ASR import EncoderASR\n",
        "\n",
        "# Directorios\n",
        "AUDIO_DIR = \"/content/drive/MyDrive/Transcripcion/Audios\"\n",
        "RESULTS_DIR = \"/content/drive/MyDrive/Transcripcion/Resultados/SpeechBrain\"\n",
        "\n",
        "# Crear directorio si no existe\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "# Cargar el modelo preentrenado de SpeechBrain (wav2vec2 para español)\n",
        "asr_model = EncoderASR.from_hparams(\n",
        "    source=\"speechbrain/asr-wav2vec2-commonvoice-14-es\",\n",
        "    savedir=\"pretrained_models/asr-wav2vec2-commonvoice-14-es\"\n",
        ")\n",
        "\n",
        "# Función de transcripción con SpeechBrain\n",
        "def transcribe_speechbrain(audio_path):\n",
        "    \"\"\"Ejecuta transcripción con SpeechBrain y mide tiempo de ejecución.\"\"\"\n",
        "    start_time = time.time()\n",
        "    transcription = asr_model.transcribe_file(audio_path)\n",
        "    execution_time = time.time() - start_time\n",
        "    return transcription, execution_time\n",
        "\n",
        "# Procesar audios con SpeechBrain\n",
        "for audio_file in os.listdir(AUDIO_DIR):\n",
        "    if audio_file.endswith(\".wav\"):\n",
        "        audio_path = os.path.join(AUDIO_DIR, audio_file)\n",
        "        transcript_file = os.path.join(RESULTS_DIR, audio_file.replace(\".wav\", \"_T.txt\"))\n",
        "        metrics_file = os.path.join(RESULTS_DIR, audio_file.replace(\".wav\", \"_Metrics.txt\"))\n",
        "\n",
        "        # Verificar si ya existe la transcripción\n",
        "        if os.path.exists(transcript_file):\n",
        "            print(f\"Skipping {audio_file}, transcription already exists.\")\n",
        "            continue\n",
        "\n",
        "        # Ejecutar transcripción\n",
        "        hypothesis, exec_time = transcribe_speechbrain(audio_path)\n",
        "\n",
        "        # Calcular WPM\n",
        "        word_count = len(hypothesis.split())  # Contar palabras\n",
        "        wpm = word_count / (exec_time / 60) if exec_time > 0 else 0  # Evitar división por cero\n",
        "\n",
        "        # Guardar transcripción\n",
        "        with open(transcript_file, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(hypothesis)\n",
        "\n",
        "        # Guardar métricas\n",
        "        with open(metrics_file, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(f\"Execution Time (s): {exec_time:.2f}\\n\")\n",
        "            f.write(f\"Word Count: {word_count}\\n\")\n",
        "            f.write(f\"WPM: {wpm:.2f}\\n\")\n",
        "\n",
        "        print(f\"SpeechBrain | Audio: {audio_file} -> Execution Time: {exec_time:.2f}s | WPM: {wpm:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2fh5UQQZoUe"
      },
      "source": [
        "## Qwen2Audio\n",
        "Este modelo fue mencionado en el overleaf, es un LLM, analisis mas profundo de audio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKXrAf-iIwxx",
        "outputId": "b669a814-e96b-4925-bc04-f6af2f97fc6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-xcy4mquq\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-xcy4mquq\n",
            "  Resolved https://github.com/huggingface/transformers to commit fc8764c9a618add64c33e83720f974750bcd0978\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.50.0.dev0) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.50.0.dev0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.50.0.dev0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.50.0.dev0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.50.0.dev0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.50.0.dev0) (2025.1.31)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.50.0.dev0-py3-none-any.whl size=10938856 sha256=25d764df34090a9e5d9c67c60134771dd8a8ccb5f24a0290f5425a90847b2a7f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ic_qmufo/wheels/04/a3/f1/b88775f8e1665827525b19ac7590250f1038d947067beba9fb\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.48.3\n",
            "    Uninstalling transformers-4.48.3:\n",
            "      Successfully uninstalled transformers-4.48.3\n",
            "Successfully installed transformers-4.50.0.dev0\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy-loader>=0.1->librosa) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.1.31)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/huggingface/transformers\n",
        "!pip install librosa soundfile torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191,
          "referenced_widgets": [
            "ba97c83734904d4f846d3c6751821af8",
            "1d6cb84e65eb4a10a66e7fb8bb8f98b8",
            "73d6f7de25804145a89c76523a07425a",
            "af1425e73e4d4227b8c44e7868b9beb7",
            "da41ecc2636b4ac1b831d22f8ed6a3c8",
            "194b3df33634426da5b0e2d0158cf490",
            "f50a7ea750a34800b57def6e742b246d",
            "653e670088174ba0aceb32497f3ce003",
            "ae5734e9a90b4966bc6a70f71ae76d55",
            "85e8e10da2dd45f1bb4332598f756bac",
            "f12ee3822594491099cd3a69d813ae72"
          ]
        },
        "id": "uLMbppGEdGG3",
        "outputId": "d2d98c66-611f-4eda-b44c-90fe9a4a740e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba97c83734904d4f846d3c6751821af8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 📌 Importar librerías\n",
        "import torch\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "from transformers import Qwen2AudioForConditionalGeneration, AutoProcessor\n",
        "\n",
        "# 📌 Configurar rutas\n",
        "audio_folder = \"/content/drive/MyDrive/Transcripcion/Audios/\"\n",
        "output_folder = \"/content/drive/MyDrive/Transcripcion/Resultados/Qwen2-Audio-7B-Instruct/\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# 📌 Cargar el modelo\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-Audio-7B-Instruct\")\n",
        "model = Qwen2AudioForConditionalGeneration.from_pretrained(\"Qwen/Qwen2-Audio-7B-Instruct\", torch_dtype=torch.float16, device_map=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 📌 Obtener archivos de audio\n",
        "audio_files = [f for f in os.listdir(audio_folder) if f.endswith(\".wav\")]\n",
        "\n",
        "# 📌 Inicializar DataFrame para métricas\n",
        "metrics = []\n",
        "\n",
        "# 📌 Iniciar temporizador general\n",
        "start_time_total = time.time()\n",
        "\n",
        "# 📌 Transcribir audios\n",
        "for audio_file in audio_files:\n",
        "    audio_path = os.path.join(audio_folder, audio_file)\n",
        "\n",
        "    # Cargar audio y medir duración\n",
        "    audio, sr = librosa.load(audio_path, sr=processor.feature_extractor.sampling_rate)\n",
        "    duration_sec = librosa.get_duration(y=audio, sr=sr)\n",
        "\n",
        "    # Definir la conversación (solo usamos el audio)\n",
        "    conversation = [{\"role\": \"user\", \"content\": [{\"type\": \"audio\", \"audio_url\": audio_path}]}]\n",
        "\n",
        "    # Procesar entrada\n",
        "    text = processor.apply_chat_template(conversation, add_generation_prompt=True, tokenize=False)\n",
        "    inputs = processor(text=text, audios=[audio], return_tensors=\"pt\", padding=True)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    # 🔹 Medir tiempo de transcripción\n",
        "    start_time = time.time()\n",
        "    generate_ids = model.generate(**inputs, max_length=256)\n",
        "    generate_ids = generate_ids[:, inputs[\"input_ids\"].size(1):]  # Remover prompt inicial\n",
        "    transcription = processor.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Calcular tiempo de ejecución y WPM\n",
        "    execution_time = end_time - start_time\n",
        "    word_count = len(transcription.split())\n",
        "    WPM = (word_count / execution_time) * 60 if execution_time > 0 else 0\n",
        "\n",
        "    # Guardar transcripción\n",
        "    output_path = os.path.join(output_folder, f\"{audio_file.replace('.wav', '_T_QA.txt')}\")\n",
        "    with open(output_path, \"w\") as f:\n",
        "        f.write(transcription)\n",
        "\n",
        "    # Guardar métricas en lista\n",
        "    metrics.append([audio_file, duration_sec, execution_time, word_count, WPM])\n",
        "\n",
        "    print(f\"✅ Transcrito: {audio_file} -> {output_path} | ⏱ Tiempo: {execution_time:.2f}s | 📝 WPM: {WPM:.2f}\")\n",
        "\n",
        "# 🔹 Tiempo total\n",
        "end_time_total = time.time()\n",
        "total_time = end_time_total - start_time_total\n",
        "print(f\"\\n🎉 Transcripción completa en {total_time:.2f} segundos.\")\n",
        "\n",
        "# 📌 Guardar métricas en CSV\n",
        "metrics_df = pd.DataFrame(metrics, columns=[\"Archivo\", \"Duración (s)\", \"Tiempo Ejecución (s)\", \"Palabras\", \"WPM\"])\n",
        "metrics_csv_path = os.path.join(output_folder, \"metricas_qwen2_audio.csv\")\n",
        "metrics_df.to_csv(metrics_csv_path, index=False)\n",
        "print(f\"📊 Métricas guardadas en {metrics_csv_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QaccN3ChlzK"
      },
      "source": [
        "Al ser mas pesado y no ser unicamente de transcripción, el modelo no pudo ser utilizado en el entorno, por consumir mucha RAM\n",
        "\n",
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAg4AAAAlCAYAAAAqT2HlAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAB7aSURBVHhe7d15dFRF3vDxb+/pTtIJSYAQwQQMi6yGXVlk8AVHkZdBHRBRQRE4apjxERxBFAkPjjM6+vIcHFREZQCfARXMBATZCUkgGCAJW0yAQAIhC3S27qT3vu8fSa7pztaA6OjU55ycw7l1q7pu3ep7f7eqbqO4dOmShCAIgiAIgh+UvhsEQRAEQRBaIgIHQRAEQRD8JgIHQRAEQRD8JgIHQRAEQRD8JgIHQRAEQRD8JgIHQRAEQRD8JgIHQRAEQRD8JgIHQRAEQRD8JgIHQRAEQRD8JgIHQRAEQRD8JgIHQRAEQRD8JgIHQRAEQRD8JgIHQRAEQfiVyMjI4IMPPsBqtfomNVFYWMjbb7/NtWvXfJNaJQKHZtjtdlatWsX69euRpF/Hfx66Zs0atm/f7rv5plRWVpKQkMDFixd9k/zicrlYtWoVkyZNYvHixX519J9DUVERixYtIjs72zfpJ3Hx4kUSEhKorKyEW3Qu2yJJEps2beK9997Dbrdf97lvq87XW55Qp7jSw6T3KvlLUi2/kkvVT35M//11DX/4h5lax0/wYbeYyWRiw4YNbN++vc3gobCwkDfffJOUlBQSExNxuVy+u7SoxcBBkiS++eYb/vSnP1FdXS1vt1qtLF68mC+//PJXc1NtiVar9d30i2WxWFrtRDfC7XZTWVmJ0+n0TfJLbm4up06d4v3332fp0qUEBARgt9vJzMzEbDb77v6zUqlUqNVq380/CafTSWVlJW63G27RufRXQEAA3MC5b6vO11uer82bNzNx4kSvvxdeeIFTp0757sqxY8eYPHkyBw4c8E2Sy9mxY4dvEmazmfnz5zN79mxMJpNv8o9u/xkHfV8xseU7m9d2p1vij+vMPPDXSi6WurlWLVFW7cbl+eVdj51uibQ8J8cv/nDeq2uln/SYKms8mCwSHo9vyi9PeHg48+fPJyoqiv3797cYPDQEDVeuXOE3v/kN06dPv67rW4uBg0KhYMyYMajVanbv3i1vT09Pp6amhnHjxqFQKLzy/FrodDqef/55pk6d+qs9xn8HFouFdu3aERERgUajQaFQYLFYWLduHSUlJb67/2xuu+02li9fTp8+fXyT/mMoFAqmTp3K888/j06n803+tzBy5EjWrl3L2rVr+eyzzxg9ejQrV6706kuSJJGSkkJUVBTJycnY7XavMhocOXKkSVpeXh75+fle226lfl3UREeo2HPaidP9ww30SoWH7EIXw2I13N1Tw/7XQnnn8WA0ql/etcruhFW7rXye+kNw1DNK9Ys+pp/b7bffzuLFi1sMHnyDhueeew69Xu9VRltUL7300lLfjQ20Wi1hYWFs2rSJQYMGYbfb+fjjj5kyZQrdu3cH4PLly2zevJmMjAyUSiUdOnRAqayLR3Jzc6mtrSUkJATqpwBOnjxJUFAQOp2OwsJCSkpKKC8v5+uvvyYiIkLet7Gamhq+/fZbdu/ejdVqpVOnTnJ0JEkS586dIykpiaysLIKCgggLC5Nv+G63m2PHjpGUlMT58+fp1KkTBoOhzTTfukuSRF5eHlu2bOHEiRNen9NwXFqtloyMDPlpJTIyUm6L5jRuO71eT1hYGEqlErPZzJkzZ1CpVGzduhWTyURMTEyTPL7t3Vo7paenYzQaUalUbNmyhbNnz3odb0P+AwcOsGPHDiorK4mMjPQadWncXsXFxbRv357Dhw8zZMgQwsPD5f0aa6m+hYWFZGRkkJ+fj9FoxOFwoNPpOHr0KMePH8doNOJ2uwkPD0epVGIymdi5cycHDhzAbrfTsWNH+dj86UcNbRoWFtYkX0REBLTSfi31W5vNxubNm8nNzW3SltXV1ezcuZPk5GQ0Gg1KpZL8/Hz5eHzZ7XbS0tLYtm0bRUVFdOjQQS6vvLycjIwMRo8ejcFgID09nZCQEHr37u1bDNQPVyYlJZGSkuLVVuXl5Zw5c4bw8HC5Dex2O9nZ2QQEBKDX61vMi097Wa1WDh486HXuW8vbUGej0cjmzZs5c+YMERERBAcHQ/1IZnPltXTOfeXk5FBTU8PYsWMxGAwYDAaio6M5dOgQnTt3pnPnzgCUlpaydetWpkyZQmZmJn369CE0NNSrHKvVitVq9UqTJImkpCT5nDSci1vJoFNwtsRN+jkn4/rpCDXUXdOSzzjZnuUgfryBjiEqUnOduDwSEcF1/crmhK3H7axLtZNf5qZzmIqgAAWlVW4Ofu8kOEBJUIACh0vi8FkXpdUeokJVKBSQW+zi+EUXEcEKAjQ/3LQraiSSc5yoVHDgjJNvTzjo10XNhatusgtcRLVToVbVjSCkn3NxzeyhU6hKzqfXKvjuvJNPk61U1Up07aDG5YEDOQ4O5DhxeSBAo8CoV6JWKbyOKbfYRXaBC60aPj1gY/8ZJ13ClSiVCj5Ps7M5w4Zeq6BzWN0xAEgSZBY4+WivjcNnXYQYFHQwKuX0xnadcGCxw8SBOrRqBZIEJy+5+PSAjb2nHQQGKIkMUaJslPfCVTefJttIPuMkMlRBwTU3+WUeOoUqUSoUbea/1UJCQhgwYABZWVmcPHmSa9eucdddd1FcXHzTQQNtBQ4A7du3p6ioiFOnTlFQUIBSqeTRRx9FoVCQmJjIihUriIyMJCAggC1btnDp0iUGDhyIUqlkw4YNWCwW+QJXVVXFypUrufPOOwkPD2fPnj2sWbOG7OxsgoKCiImJkS/iDa5du8brr7+OzWajV69ebN++nczMTIYNG4ZKpSIxMZHVq1fTu3dvNBoNq1evRqFQ0KtXL9xuN6tXr2b37t0MHDiQwsJC1q9fT1xcHEFBQS2mhYaGetXd5XLx0Ucf8fnnn9OtWzfcbjf/+Mc/5M+pqqrivffeY+/evUiSREBAABs3bsRqtdK/f/8moxaSJJGYmMiqVavo3LkzKpWK9evXY7fb6devH4WFhbz77rskJyejVCoxGo307NmTtLQ03nnnHWJiYjAajWzatImioiLi4uIoLy9vsZ3UajXp6elkZ2eTmZlJbGwsJ0+eZOfOnQwdOhSDwUBZWRkJCQmUlpYSFxdHamoqSUlJDBkyhMDAQFwuFx9++CHbt2+nd+/eFBcXs3nzZmw2GyNGjGg2cGitvocPHyYpKYmKigrOnj2Lx+OhU6dOfPrpp5SWlnLx4kWqq6sZMmQI+fn5LFmyBJ1OR2xsLNu2bePIkSMMHToUrVbrVz8qLCxkzZo1DB8+XL7g79mzh2PHjjF8+PBW+5nFYmm2354+fZqYmBhOnjxJYmIigwcPJjg4mKKiIpYsWUJFRQXR0dEkJSWRlpZGbm4uI0eORKPReNWtpqaGt956i7Nnz9K/f39ycnLYsGED/fv3Jyws7LoCh7y8PJYsWUJoaCi33347W7duJSMjg+HDh+N2u1m1ahVdu3alffv2AJw9e5Z169YxevRoLl261GJejUbj1V6+N/rWPlej0cj97+DBg8TExHD58mXWrVtHly5d6Ny5c4vltXTOfeXk5FBdXc3w4cPlbQ6Hg+TkZPr3709UVBTUT1OUlpby6KOPkpubi9Vq9WrHnJwcJEkiNDSU8vJy+vXrB/UBx9dff82YMWPIz8//SQIHAL1OwdcZdnp1UtErSo3TLfH+bitajYI5Y/XU2CX+uN6MQatkSDcNpVUeZq2uIvGYA61awcHvnfxvmo1BXTVo1Epe2mBBAQyL1XCu1E38Z2aOnHdxf38teq2Cv26tZfcpB5MGBXgFDmdL3Ly43kziUTt7Tzspt3j47QAd27McfLjXykNxOoICFFgd8MZXNVwoc3N/f52cb/N3NnafcnLJ5GFbpp3Ca24GRKt5+X8tXDJ5KKn0sOukg4FdNYQaFF7H9OURO8sTa9nynZ28EjdHL7jYddLB1uN2UvMcnCvxkHjUTt/6ERqnW+KdbVYSttRgc0gUmtx8kmxFqYDBXTVNgofGgYNCAe9ss/LalxYKrrk5X+rmn4dtlFR5GNVTg0qpYNdJB7M/NnOi0EWBycXnaXa2ZzrIL/PwwAAdXxyx81/r69ZMWGzw0b5atGoFg7p6f+9vNd/g4fz58+zYseOmgwZam6pooFar+d3vfseJEyfYs2cPkydPRq1WU1payp49e1i8eDHx8fE8/fTTLF++nJycnOtaRBYQEMBrr73Giy++SM+ePX2TOX/+PHq9nj/84Q9MmDCBhIQE4uLicLlclJaWcuDAAV599VWmTp3K1KlTWbhwIXv27KGkpISqqiq+//574uPjmThxIi+++CJPPPEEkiS1mubr7NmznD59mrfffptZs2Yxe/ZsXn/9dXbu3ElBQQHUP7k99NBDxMfHM2vWLOLj48nOzsZisfgW51Xv2bNnM2vWLBYuXEhGRoa8utXpdDJ9+nReeeUVJk6ciNPp5MqVK3JbT5kyhcWLF5Obm8vVq1dbbacGGo2GN954gylTprBo0SL0er08B7xnzx5iYmJYsmQJ48ePZ8mSJURHR7Nz506ov6Dm5uayfPlyHnvsMeLj45k2bRo2m/f8a4O26vvggw8SHx9Pr169WLlyJc8++ywxMTEkJCQQExPDa6+9xssvv4xarSYpKYkHH3yQF198kQceeICEhARqa2vJyMiQP6+tftQWf9qvsaCgIBYtWiQfV8eOHcnLy0OSJLZu3UrPnj1ZunQpU6ZM4W9/+xuRkZG+RcjKysrk4cUJEybwpz/9ibvvvptDhw757tqmgoICHn30UblfJyQkYLFYyM/PJzQ0lNjYWI4ePSrvn5mZSY8ePWjXrl2redviT16NRsNbb70l9+snn3ySLVu2UFNT41WWy+Xy65z7stvtmEwmTCYTZWVlbNiwAaVSSY8ePaC+3PT0dAYPHozBYGDIkCF89913TT5foVAwatQoTp06Jafl5uYSFhZGdHS01763Ws9OamI6qNh3xoHTLXGlQuLkJRcje9TdYH19nmaj2gr/eimEz18w8s3LIXTtoGLlrlpCDEq6R6rILHBhc8LpSy6sTiir8nC+zI3J4uFMkYv+XdTNlg1wR0cVB14LJWlBKB1D2rx9yO6K0XBwSTtSlrRjxig9Gfku3B4FSfNDGdRVw4S7tHz/t3DG92saFAJ4JInFkwNJWdKO/3kqiKtmD3fepib59XZsWxDCbe2UfJNVN7WUXeBiS4aNP08NImlBKFsXhPLc/zGwPsVGXknz3+cG2QUuvvrORvx4A6lvhHFoaRhLJgeyPctBWp6TqloPq/fW0rOTin2L25GyJIxP5xhR1TdFrUNi1wk79/XRsuW/Qvn8BSNv/j6IyFCl13TTT6XxtMXx48d/lKABfwIHgKioKMaPH09cXByxsbFQf6EwGo1069ZN3q9jx4706tWL8+fPN8rduh49etChQwffzbLIyEjKysr44IMPOHr0KJIkMWHCBAIDAykoKMDhcFBUVERqaiqpqakUFRVRW1tLSUkJQUFBdOjQgQ8++IC9e/dSXFzMmDFjiImJaTXN15kzZ+jWrRudOnWSt0VHR9OxY0euXLkC9TeShgsU9YtU3G43DodD3tagoKAAg8FAly5d5G19+/ZlxYoV8pNgWFiY15OQRqPh97//Pf3795cvjg1D4BaLpdV2ajB06FCMRiMAgYGBREVFYTKZsFqtnD59mqCgINLT00lNTSU9PR2VSsWFCxew2+3k5eURExPjda769OnT5Mm+QVv19VdVVRUXLlxAkiTS0tJITU3lxIkTaLVa8vLy5P3a6kdt8af9GuvevTvt2rUDQK/X0759e0wmEzabjUuXLnH33XfLw+pqtZqhQ4f6lPCDrl27MmvWLFwuFyaTiaqqKsLCwm5oAd64ceO4//77qaiowGQy4XK50Ov1WCwWFAoFw4YN49SpU5jNZsxmM6dOnWLEiBFt5m2LP3kHDBgg9z+AuLg4HA5Hk+P095z7Sk1NZebMmcycOZM5c+Zgt9tZuHCh/JmXL1+msLBQHkXo27cvNpuNwsJCn5IgNjYWh8PBxYsXsdvtJCcnc++99zY72nErhRoUjOyhIbvQxZUKD8fyHdTYJEb3avr0arFJHLvgQpLgg702Fm2q4S9brVgdcMnkweH0MKSbhvwyNyazh8PnXNzXR0OPTmqOX6grv9zi4b4+LR/jtHsCCDH4ddvw8lCclgANKBQwsKsam0Oiqtb/1YgdjEqG3VF3zOFBSvQaBeP6adGqFRh0CsKClLhcdTfmjHwXLjfsP+1k0aYaXv2ihhOFLix2uGxq/TMz8l0EBSh4eIgOlbKuvuP6aYlqpyQ5x0llLZRWSzw0UEe7wLrg6q5oNXd3r2szg1ZBXIyGPacczPtHNdsyHdzdXcP/Haj7Va3X8LsHqFQqVCqV17C7UqlsMgzfsWNHSktLvba1xrdMX9HR0bz77rt07tyZTZs2MWvWLN555x35SaC2tpYTJ06QlZVFVlYWZ8+eZfDgwRiNRnQ6HS+//DKPPPII6enpLFiwgPj4eM6fP99qWnN866nT6QgJCaGsrMxrP38113aNNZd+6NAhnnnmGVasWMGHH37IwoULKS4uBj/aifpjaE1hYaHcjllZWeh0Ovr27Sun+7aBXq9vdoqiQWv1vR4N61ga1y0qKsoryPOt2/Xyp/1uRmvRfU1NDcuWLWP+/PmsXbuWN954g02bNvnu5pe8vDxmz57N8uXL+eSTT1i0aJHXmwWxsbGoVCoKCwspLCxEpVLJ7dhW3tb4k9d3aL/hJmxvZoGiP+fc13333cfWrVv57LPPiImJYejQoYSFhcnpp0+fpqSkhGXLljF79mxeeeUVLl++TEpKilc51A/zDhw4kJSUFK5cuUJFRQW9evXy3e0nMbqXBotNIv2ck21ZDu68TU2vqObXegDofe77d96m5r4+GrQaGNFDg90pkZHvJKfIxbh+OgbcriIj30lGvhODrm5UoiXqG7z53Wi+G6VVg0r5wxN+WJCSCXE6v0ZJlIq6vwYBGgWhBiVmqwez1YPdKRFWHzRAXXChVPzwWX/8rYF3Hg/CbJVYtqWGe5dX8Jek2p9lxKHxQsiBAwe2uGDyerXc+9qg1WqpqanBZrPJF0WXy8WFCxdaHCqWJAnPdb7z4na70ev1PPbYYzz22GOUlpaSkJBATk4OWq2WyMhIZs2aJS+ycrvdSJIkP+253W5GjhzJvffei8vl4v3332f79u3Mmzev1bTGDAYDlZWV2O12eUW5xWKhuLiYe++912tff2i1Wmpra3E4HHLbWa1WKisrW3xqrqqqYuPGjcybN0+ex21Y6EIb7TR48GCf0rwplUp0Oh2jR49mzJgx8nan04larUahUGAwGLDb7bhcLrltq6qqWnz7oa36+kutVmMwGJg0aZLXWw2Nz8WNani9seHfLbVf165dvfK1pqEtG/+giiRJ5OTkeO3X2MGDB3E4HKxcuVLuD+vXr2/yJN4Wu93Oxo0beeihh3jkkUegflHo0qU/LGMKDg6mb9++pKWlAXDXXXcRGBjoV96W+Jv36tWrSJIkB3jl5eV4PB555KbBzZ7ziIgIJk2axBdffEHv3r0JDQ3FarXKgWzjdRA5OTl89dVXVFRUNKlHXFwcn3zyCYGBgfII48/xmnD3SBUxEUq+SLdRWiUxa0wAQQFNb8RqlQKdBroYVCx71CA/4ZZUeggNVBKgASIUdGqn4ot0O3aXRK8oNQatgu3ZFqpqPfTspCI8uGnZ/nJ5wOqUgBsv42YF6xVo1Arm3R9IdERdoFBtlXC6JcKDWg8cgvUKau0SFTUSHevXV5ssdeskRvYMIDJUSXujkuTvnYzrp0WjUlBeI3HxmocATd3CyspaD8NiNUyI0+H2wPu7atl02MbkIVp6drrhW+51axw0NExPXL16lTfffJP9+/cD3PCUReut2Io77rgDrVbLjh07cLlcSJLEoUOHOHfuHHFxcVA/XN+wSlmSJA4ePHjdv1CVmprKyy+/LD/Zq9VqNBoNKpWKO+64A0mS+Pbbb+WAITU1lVdeeYXq6mpKSkqYP38+6enpUD93qdVq0el0rab5GjBgAMXFxaSkpCBJEm63m2+//RaXyyVP3VyPrl27IkkSu3btkuu9Y8cOVqxY0eKaAaVSiVarxWKxIEkSLpeLPXv2yO3ZWju1RafTMWrUKL788kt56sVsNvPGG2/Ir+L27t2bc+fOcejQISRJwm6389VXX7V4Ptuqb2ucTicWiwW3201wcDADBgxg48aN8kX7ypUrLFiwgJMnT/pmbVFQUBB2u12ecy8rKyM5OVlOv5n2a0yn0zF+/Hi++OIL9u7di8lkYteuXRw8eNB3V5ler8dms8nTWgUFBa3u3xKVSoVOp6OmpkbuV4cPH26yRiEuLo7vvvuOzMxMBg0adF15m+Nv3tTUVLKysqA+UE5MTCQ2NtbrrQYAo9F40+f8nnvuISIigq1btyJJEhcvXqSiooKBAwcSHh4u/zUEJr51BejWrRvBwcH861//YtSoUc2OaGVnZ7N27dofbWSqOSEGJff11XH6shuXW5KHxX0FaGDCXVoO5TlYvc9GcaWH3Scd/O69Sv6aZEGS6qY++ndRc/yiky7hKjqG1I0wqJQKTl92c08PzXUNqUeFKimt8rAuxcYlk5uP91nJKWp9HUFjSmXd0/qJS27+dcxOwbXre7BszogeGkBieaKF3GIXucUu5n5SzYwPqrla3Xr5o3pqCNAqSNjyQ97liRY8HhjbW0tEsJJJg3RsO25nwecWvjxiZ87HVXx/pe6YzTYPc9dU88xH1eQUubhS4ebiVQ9ajfdbKrdac0GDXq9v81VNf91w4GA0GomPjyctLY3HH3+c6dOns3r1aubOnSsvILr//vspKytjxowZzJw5k/z8fPk1Tn+NGDGCfv36ER8fz7PPPstzzz1HXFwc/fr1w2g0MnfuXPbt28eTTz7J9OnT+fTTT5k7dy5Go5HIyEhmzJjB3//+d2bMmMGTTz5JQUEBDz/8cKtpvqKionj++edZv34906dPZ9q0aezbt4958+Y1uej5IzQ0lHnz5rFv3z6mTZvG9OnT2b17N3PmzGlxTj04OJiHH36YNWvWyPO49vpX1GijnfwxatQohgwZQnx8PDNmzOCpp56ic+fOjB07FuqH8ufOncvq1at56qmnmDlzJiqVqsXh27bq25KQkBAGDx7M0qVLWbJkCXa7nYcffhij0cjTTz/NjBkzeOGFFxg7dqzXNEpbIiMjGTduHH/+85+ZMWMGr776qteT5822X2PDhg1j1qxZ/POf/+S5557j9OnTPP744767yYYMGYLRaGT27Nny1M6AAQN8d2uTWq1m8uTJ7N27V27zEydONPnOdevWjc6dO9OxY0d53Y6/eZvjb97hw4fz2Wef8cQTT/DEE09gNpub/eEZhUJx0+dcp9Mxbdo0UlNTycvLIzMzk27duslriBq0a9eO3r17s3///iYLYXU6HUOHDiU6Otpr/VJj33//PQcPHqSiosI36Uc1ooeG4AAFd96mJqZ9y8HsxIE6Hrtbz9931fKb5RX8YZ2ZoXdoePEBg/w2wd3d694sGNJNQ4AGwoMV9OykIjigLqi4HmN6axh2h4ZPDlgZ91YlOUUu7unedP1FSwxaBdPuCeCa2cMr/6y7Wd+sru1VLH04iBMFLia9W8Wkd6u4Zvbwl8eCaG9s/ZYXHaFi+e8DuVLhkfOeKHCx7NFAekbVtfvM0QH88bcGjpxz8s62WobeoZHXhRj1SpY+EoTVKTH5/1Ux7q1KUnIdLJwYSHREy+ftx9RS0NDgxwgeFJcuXbqpiRdJkqiursbj8RAcHNzkIuB2uzGbzajVaoKCgrzSrofVaqW2thaDwdBkaKXhM6i/Yfk+JbpcLsxms/xqY+Mnh9bSfLX1OdfrRsqz2+1YLJZm24E22skfbeVvaK+G9/7b0lZ9W+J0OlEoFF79yWKxYLfb5d9TuBFWqxWbzdZsX21Ib+34/dEwwtL4tcsdO3Zw5swZXnrppWb7WMP3SJIkv/tCSxrOkUajue7v3K3O29DnFQpFm983fqRz/p/I5oSqWg86DYTewGLG6yFJUF5T9yQfFtj8byW0xe0Bh0tCr72BzC1we6DcUl+vIKX85oM/WstrsUlcNXvoWh/A1f2SZ90i4P95KgiNqm7KorzGg9sNoYEKtOof77haYzKZWLZsGfn5+c0GDY01DjAmTZrEzJkzm70mNuemAwdBELx988038qvKERERmM1m3nrrLUaOHMmDDz7ou7sgCL8QTrfEgs8tHDnnZPmUIAZ11fBNlp2/bath/oRAnhxZ95PsP6eMjAyOHj3KzJkzWwwaGhQWFrJx40aeeeaZFt+Qa44IHAThR2a1Wvnoo49ITU0lNDSUyspKxo4dy5w5c/yO6AVB+PdUXOnhj+vqfgCK+rcwnhql56UH9T/ZyMLPTQQOgnCLNAyz38y0hyAI/34apiJcbgjUKZp9y+XXTAQOgiAIgiD47TqWiwiCIAiC8J9OBA6CIAiCIPhNBA6CIAiCIPhNBA6CIAiCIPhNBA6CIAiCIPhNBA6CIAiCIPhNBA6CIAiCIPjt/wOzj4diCKDREQAAAABJRU5ErkJggg==)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDOAH8M_SXp_"
      },
      "source": [
        "## Kaldi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gGG4KUYSYoC"
      },
      "outputs": [],
      "source": [
        "# Instalar Vosk y dependencias\n",
        "%%capture\n",
        "!pip install vosk\n",
        "!apt-get install ffmpeg -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeVA2qIGSvaj",
        "outputId": "930a6142-662c-4a79-c98d-3a9917c56ad2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-03-18 00:52:12--  https://alphacephei.com/vosk/models/vosk-model-small-es-0.42.zip\n",
            "Resolving alphacephei.com (alphacephei.com)... 188.40.21.16, 2a01:4f8:13a:279f::2\n",
            "Connecting to alphacephei.com (alphacephei.com)|188.40.21.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 39817833 (38M) [application/zip]\n",
            "Saving to: ‘vosk-model-small-es-0.42.zip’\n",
            "\n",
            "vosk-model-small-es 100%[===================>]  37.97M  13.9MB/s    in 2.7s    \n",
            "\n",
            "2025-03-18 00:52:16 (13.9 MB/s) - ‘vosk-model-small-es-0.42.zip’ saved [39817833/39817833]\n",
            "\n",
            "Archive:  vosk-model-small-es-0.42.zip\n",
            "   creating: vosk-model-small-es-0.42/\n",
            "   creating: vosk-model-small-es-0.42/graph/\n",
            "   creating: vosk-model-small-es-0.42/graph/phones/\n",
            "  inflating: vosk-model-small-es-0.42/graph/phones/word_boundary.int  \n",
            "  inflating: vosk-model-small-es-0.42/graph/Gr.fst  \n",
            "  inflating: vosk-model-small-es-0.42/graph/HCLr.fst  \n",
            "  inflating: vosk-model-small-es-0.42/graph/disambig_tid.int  \n",
            "   creating: vosk-model-small-es-0.42/am/\n",
            "  inflating: vosk-model-small-es-0.42/am/final.mdl  \n",
            "  inflating: vosk-model-small-es-0.42/README  \n",
            "   creating: vosk-model-small-es-0.42/conf/\n",
            "  inflating: vosk-model-small-es-0.42/conf/model.conf  \n",
            "  inflating: vosk-model-small-es-0.42/conf/mfcc.conf  \n",
            "   creating: vosk-model-small-es-0.42/ivector/\n",
            "  inflating: vosk-model-small-es-0.42/ivector/final.dubm  \n",
            "  inflating: vosk-model-small-es-0.42/ivector/global_cmvn.stats  \n",
            "  inflating: vosk-model-small-es-0.42/ivector/final.ie  \n",
            "  inflating: vosk-model-small-es-0.42/ivector/final.mat  \n",
            "  inflating: vosk-model-small-es-0.42/ivector/splice.conf  \n",
            "  inflating: vosk-model-small-es-0.42/ivector/online_cmvn.conf  \n",
            "🔄 A053.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A069.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A065.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A066.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A060.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A062.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A068.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A061.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A067.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A064.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A063.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A056.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A055.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A001.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A058.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A057.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A059.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A032.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A035.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A031.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A054.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A029.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A033.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A030.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A028.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A026.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A034.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A019.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A025.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A022.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A023.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A027.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A024.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A020.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A016.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A014.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A018.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A021.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A015.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A010.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A008.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A009.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A013.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A012.wav ya ha sido procesado. Omitiendo...\n",
            "✅ Kaldi | Audio: A007.wav -> Execution Time: 8.56s, WPM: 0.00\n",
            "🔄 A017.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A002.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A039.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A036.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A037.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A042.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A003.wav ya ha sido procesado. Omitiendo...\n",
            "✅ Kaldi | Audio: A038.wav -> Execution Time: 2.53s, WPM: 0.00\n",
            "🔄 A005.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A040.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A004.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A011.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A046.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A048.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A006.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A041.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A045.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A047.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A044.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A043.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A049.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A052.wav ya ha sido procesado. Omitiendo...\n",
            "🔄 A050.wav ya ha sido procesado. Omitiendo...\n",
            "✅ Kaldi | Audio: A051.wav -> Execution Time: 4.28s, WPM: 0.00\n"
          ]
        }
      ],
      "source": [
        "# Importar librerías necesarias\n",
        "import os\n",
        "import time\n",
        "import wave\n",
        "import json\n",
        "from vosk import Model, KaldiRecognizer\n",
        "from pathlib import Path\n",
        "\n",
        "# Definir rutas\n",
        "AUDIO_DIR = \"/content/drive/MyDrive/Transcripcion/Audios\"\n",
        "RESULTS_DIR = \"/content/drive/MyDrive/Transcripcion/Resultados\"\n",
        "MODEL_NAME = \"Kaldi_Vosk\"  # Nombre del modelo para organizar resultados\n",
        "MODEL_DIR = os.path.join(RESULTS_DIR, MODEL_NAME)\n",
        "\n",
        "# Crear carpeta de resultados si no existe\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "# Descargar modelo de Vosk en español si no existe\n",
        "if not os.path.exists(\"model\"):\n",
        "    !wget https://alphacephei.com/vosk/models/vosk-model-small-es-0.42.zip\n",
        "    !unzip vosk-model-small-es-0.42.zip\n",
        "    !mv vosk-model-small-es-0.42 model\n",
        "\n",
        "# Cargar el modelo de Vosk\n",
        "model = Model(\"model\")\n",
        "\n",
        "# Función para calcular Words Per Minute (WPM)\n",
        "def words_per_minute(text, audio_path):\n",
        "    with wave.open(audio_path, \"rb\") as wf:\n",
        "        duration = wf.getnframes() / wf.getframerate()  # Duración en segundos\n",
        "    words = len(text.split())\n",
        "    return (words / duration) * 60 if duration > 0 else 0\n",
        "\n",
        "# Función para transcribir audio\n",
        "def transcribir_audio(ruta_audio):\n",
        "    with wave.open(ruta_audio, \"rb\") as wf:\n",
        "        if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getcomptype() != \"NONE\":\n",
        "            raise ValueError(\"El archivo de audio debe estar en formato WAV mono PCM de 16 bits\")\n",
        "\n",
        "        recognizer = KaldiRecognizer(model, wf.getframerate())\n",
        "        texto_transcrito = \"\"\n",
        "\n",
        "        while True:\n",
        "            data = wf.readframes(4000)\n",
        "            if len(data) == 0:\n",
        "                break\n",
        "            if recognizer.AcceptWaveform(data):\n",
        "                result = json.loads(recognizer.Result())\n",
        "                texto_transcrito += result.get(\"text\", \"\") + \" \"\n",
        "\n",
        "        return texto_transcrito.strip()\n",
        "\n",
        "# Procesar audios\n",
        "for audio_file in os.listdir(AUDIO_DIR):\n",
        "    if audio_file.endswith(\".wav\"):\n",
        "        audio_path = os.path.join(AUDIO_DIR, audio_file)\n",
        "        transcript_file = os.path.join(MODEL_DIR, audio_file.replace(\".wav\", \"_T_K.txt\"))\n",
        "        metrics_file = os.path.join(MODEL_DIR, audio_file.replace(\".wav\", \"_Metrics.txt\"))\n",
        "\n",
        "        # 📌 Verificar si ya existen los archivos de transcripción y métricas\n",
        "        if os.path.exists(transcript_file) and os.path.exists(metrics_file):\n",
        "            print(f\"🔄 {audio_file} ya ha sido procesado. Omitiendo...\")\n",
        "            continue  # Saltar este archivo\n",
        "\n",
        "        # ⏳ Medir tiempo de ejecución y transcribir\n",
        "        start_time = time.time()\n",
        "        transcript = transcribir_audio(audio_path)\n",
        "        execution_time = time.time() - start_time\n",
        "\n",
        "        # 📊 Calcular WPM\n",
        "        wpm = words_per_minute(transcript, audio_path)\n",
        "\n",
        "        # 💾 Guardar transcripción\n",
        "        with open(transcript_file, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(transcript)\n",
        "\n",
        "        # 💾 Guardar métricas\n",
        "        with open(metrics_file, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(f\"Execution Time (s): {execution_time:.2f}\\n\")\n",
        "            f.write(f\"WPM: {wpm:.2f}\\n\")\n",
        "\n",
        "        print(f\"✅ Kaldi | Audio: {audio_file} -> Execution Time: {execution_time:.2f}s, WPM: {wpm:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gy29LtlSbSDJ"
      },
      "source": [
        "## Nvidia NeMo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12UmbWPrbT1U"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install nemo_toolkit['asr'] torchaudio pydub\n",
        "!apt-get install sox\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6t5VOGgmeJJ2",
        "outputId": "ae948c8c-ec87-4341-ee90-47daf8097695"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cargando modelo NeMo STT en español...\n",
            "[NeMo I 2025-03-17 00:36:34 nemo_logging:393] Found existing object /root/.cache/torch/NeMo/NeMo_2.2.0/stt_es_conformer_transducer_large/89ef8b9d7053f53a9eec342fd52801eb/stt_es_conformer_transducer_large.nemo.\n",
            "[NeMo I 2025-03-17 00:36:34 nemo_logging:393] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.2.0/stt_es_conformer_transducer_large/89ef8b9d7053f53a9eec342fd52801eb/stt_es_conformer_transducer_large.nemo\n",
            "[NeMo I 2025-03-17 00:36:34 nemo_logging:393] Instantiating model from pre-trained checkpoint\n",
            "[NeMo I 2025-03-17 00:36:48 nemo_logging:393] Tokenizer SentencePieceTokenizer initialized with 128 tokens\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[NeMo W 2025-03-17 00:36:48 nemo_logging:405] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /data/dataset/train/tarred_audio_manifest.json\n",
            "    sample_rate: 16000\n",
            "    batch_size: 16\n",
            "    shuffle: true\n",
            "    num_workers: 8\n",
            "    pin_memory: true\n",
            "    use_start_end_token: true\n",
            "    trim_silence: false\n",
            "    max_duration: 20\n",
            "    min_duration: 0.1\n",
            "    is_tarred: true\n",
            "    tarred_audio_filepaths: /data/dataset/train/audio__OP_0..511_CL_.tar\n",
            "    \n",
            "[NeMo W 2025-03-17 00:36:48 nemo_logging:405] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath:\n",
            "    - /data/dev/fisher/dev_fisher_mounted_files_manifest.json\n",
            "    - /data/dev/mcv7/dev_mcv7_mounted_files_manifest.json\n",
            "    - /data/dev/mls/dev_mls_mounted_files_manifest.json\n",
            "    - /data/dev/voxpopuli/dev_voxpopuli_mounted_files_manifest.json\n",
            "    sample_rate: 16000\n",
            "    batch_size: 8\n",
            "    shuffle: false\n",
            "    num_workers: 8\n",
            "    pin_memory: true\n",
            "    use_start_end_token: true\n",
            "    \n",
            "[NeMo W 2025-03-17 00:36:48 nemo_logging:405] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    batch_size: 16\n",
            "    shuffle: false\n",
            "    num_workers: 8\n",
            "    pin_memory: false\n",
            "    use_start_end_token: true\n",
            "    \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2025-03-17 00:36:48 nemo_logging:393] PADDING: 0\n",
            "[NeMo I 2025-03-17 00:36:50 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
            "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0}\n",
            "[NeMo I 2025-03-17 00:36:50 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
            "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[NeMo W 2025-03-17 00:36:50 nemo_logging:405] No conditional node support for Cuda.\n",
            "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
            "    Reason: CUDA is not available\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2025-03-17 00:36:50 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
            "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[NeMo W 2025-03-17 00:36:50 nemo_logging:405] No conditional node support for Cuda.\n",
            "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
            "    Reason: CUDA is not available\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2025-03-17 00:36:52 nemo_logging:393] Model EncDecRNNTBPEModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.2.0/stt_es_conformer_transducer_large/89ef8b9d7053f53a9eec342fd52801eb/stt_es_conformer_transducer_large.nemo.\n",
            "Procesando A053.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:09<00:00,  9.62s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A053.wav -> Execution Time: 9.67s, WPM: 123.78\n",
            "Procesando A069.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:10<00:00, 10.30s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A069.wav -> Execution Time: 10.33s, WPM: 114.67\n",
            "Procesando A065.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:06<00:00,  6.29s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A065.wav -> Execution Time: 6.32s, WPM: 132.14\n",
            "Procesando A066.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:10<00:00, 10.88s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A066.wav -> Execution Time: 10.90s, WPM: 114.17\n",
            "Procesando A060.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:19<00:00, 19.21s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A060.wav -> Execution Time: 19.23s, WPM: 144.11\n",
            "Procesando A062.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:09<00:00,  9.66s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A062.wav -> Execution Time: 9.69s, WPM: 133.66\n",
            "Procesando A068.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:04<00:00,  4.83s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A068.wav -> Execution Time: 4.86s, WPM: 128.80\n",
            "Procesando A061.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:10<00:00, 10.21s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A061.wav -> Execution Time: 10.24s, WPM: 134.46\n",
            "Procesando A067.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:10<00:00, 10.74s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A067.wav -> Execution Time: 10.77s, WPM: 114.93\n",
            "Procesando A064.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:08<00:00,  8.94s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A064.wav -> Execution Time: 8.97s, WPM: 146.56\n",
            "Procesando A063.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:10<00:00, 10.63s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A063.wav -> Execution Time: 10.66s, WPM: 147.07\n",
            "Procesando A056.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:11<00:00, 11.17s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A056.wav -> Execution Time: 11.20s, WPM: 137.34\n",
            "Procesando A055.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:11<00:00, 11.51s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A055.wav -> Execution Time: 11.53s, WPM: 116.47\n",
            "Procesando A001.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:06<00:00,  6.96s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A001.wav -> Execution Time: 6.99s, WPM: 87.78\n",
            "Procesando A058.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:12<00:00, 12.55s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A058.wav -> Execution Time: 12.58s, WPM: 165.40\n",
            "Procesando A057.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:15<00:00, 15.96s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A057.wav -> Execution Time: 16.00s, WPM: 152.48\n",
            "Procesando A059.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:17<00:00, 17.95s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A059.wav -> Execution Time: 17.98s, WPM: 114.80\n",
            "Procesando A032.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:08<00:00,  8.81s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A032.wav -> Execution Time: 8.84s, WPM: 158.64\n",
            "Procesando A035.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:08<00:00,  8.21s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A035.wav -> Execution Time: 8.24s, WPM: 93.71\n",
            "Procesando A031.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:09<00:00,  9.81s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A031.wav -> Execution Time: 9.83s, WPM: 204.52\n",
            "Procesando A054.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:08<00:00,  8.30s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A054.wav -> Execution Time: 8.32s, WPM: 125.15\n",
            "Procesando A029.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:09<00:00,  9.03s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A029.wav -> Execution Time: 9.05s, WPM: 153.23\n",
            "Procesando A033.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:17<00:00, 17.54s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A033.wav -> Execution Time: 17.56s, WPM: 150.10\n",
            "Procesando A030.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:07<00:00,  7.63s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A030.wav -> Execution Time: 7.66s, WPM: 167.91\n",
            "Procesando A028.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:09<00:00,  9.51s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A028.wav -> Execution Time: 9.53s, WPM: 172.87\n",
            "Procesando A026.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:10<00:00, 10.05s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A026.wav -> Execution Time: 10.07s, WPM: 171.29\n",
            "Procesando A034.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:23<00:00, 23.06s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A034.wav -> Execution Time: 23.08s, WPM: 92.93\n",
            "Procesando A019.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:16<00:00, 16.88s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A019.wav -> Execution Time: 16.91s, WPM: 126.94\n",
            "Procesando A025.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:07<00:00,  7.46s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A025.wav -> Execution Time: 7.48s, WPM: 155.29\n",
            "Procesando A022.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:09<00:00,  9.19s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A022.wav -> Execution Time: 9.21s, WPM: 222.78\n",
            "Procesando A023.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:14<00:00, 14.40s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A023.wav -> Execution Time: 14.43s, WPM: 160.04\n",
            "Procesando A027.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:08<00:00,  8.50s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A027.wav -> Execution Time: 8.53s, WPM: 193.74\n",
            "Procesando A024.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:08<00:00,  8.49s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A024.wav -> Execution Time: 8.52s, WPM: 145.23\n",
            "Procesando A020.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:08<00:00,  8.99s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A020.wav -> Execution Time: 9.01s, WPM: 161.09\n",
            "Procesando A016.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:20<00:00, 20.61s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A016.wav -> Execution Time: 20.64s, WPM: 140.70\n",
            "Procesando A014.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:19<00:00, 19.57s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A014.wav -> Execution Time: 19.60s, WPM: 150.85\n",
            "Procesando A018.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:23<00:00, 23.55s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A018.wav -> Execution Time: 23.58s, WPM: 160.94\n",
            "Procesando A021.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:08<00:00,  8.13s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A021.wav -> Execution Time: 8.15s, WPM: 98.06\n",
            "Procesando A015.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:22<00:00, 22.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A015.wav -> Execution Time: 22.12s, WPM: 143.49\n",
            "Procesando A010.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:06<00:00,  6.42s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A010.wav -> Execution Time: 6.45s, WPM: 144.24\n",
            "Procesando A008.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:05<00:00,  5.43s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A008.wav -> Execution Time: 5.46s, WPM: 164.32\n",
            "Procesando A009.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:07<00:00,  7.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A009.wav -> Execution Time: 7.10s, WPM: 170.04\n",
            "Procesando A013.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:22<00:00, 22.83s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A013.wav -> Execution Time: 22.85s, WPM: 138.24\n",
            "Procesando A012.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:17<00:00, 17.59s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A012.wav -> Execution Time: 17.62s, WPM: 125.69\n",
            "Procesando A007.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:04<00:00,  4.42s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A007.wav -> Execution Time: 4.45s, WPM: 167.56\n",
            "Procesando A017.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:23<00:00, 23.60s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A017.wav -> Execution Time: 23.62s, WPM: 112.37\n",
            "Procesando A002.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:05<00:00,  5.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A002.wav -> Execution Time: 5.10s, WPM: 103.37\n",
            "Procesando A039.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:05<00:00,  5.29s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A039.wav -> Execution Time: 5.32s, WPM: 203.78\n",
            "Procesando A036.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:04<00:00,  4.33s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A036.wav -> Execution Time: 4.36s, WPM: 157.60\n",
            "Procesando A037.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:04<00:00,  4.58s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A037.wav -> Execution Time: 4.61s, WPM: 172.87\n",
            "Procesando A042.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:10<00:00, 10.34s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A042.wav -> Execution Time: 10.38s, WPM: 150.42\n",
            "Procesando A003.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:04<00:00,  4.23s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A003.wav -> Execution Time: 4.26s, WPM: 108.49\n",
            "Procesando A038.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:03<00:00,  3.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A038.wav -> Execution Time: 3.13s, WPM: 173.85\n",
            "Procesando A005.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:20<00:00, 20.58s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A005.wav -> Execution Time: 20.61s, WPM: 150.44\n",
            "Procesando A040.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:12<00:00, 12.81s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A040.wav -> Execution Time: 12.84s, WPM: 137.19\n",
            "Procesando A004.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:46<00:00, 46.35s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A004.wav -> Execution Time: 46.38s, WPM: 144.12\n",
            "Procesando A011.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:17<00:00, 17.01s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A011.wav -> Execution Time: 17.05s, WPM: 154.67\n",
            "Procesando A046.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:05<00:00,  5.12s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A046.wav -> Execution Time: 5.14s, WPM: 157.65\n",
            "Procesando A048.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:05<00:00,  5.53s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A048.wav -> Execution Time: 5.56s, WPM: 129.04\n",
            "Procesando A006.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [01:10<00:00, 70.99s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A006.wav -> Execution Time: 71.03s, WPM: 146.05\n",
            "Procesando A041.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:09<00:00,  9.72s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A041.wav -> Execution Time: 9.74s, WPM: 128.76\n",
            "Procesando A045.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:06<00:00,  6.99s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A045.wav -> Execution Time: 7.03s, WPM: 157.26\n",
            "Procesando A047.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:08<00:00,  8.84s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A047.wav -> Execution Time: 8.87s, WPM: 129.37\n",
            "Procesando A044.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:11<00:00, 11.51s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A044.wav -> Execution Time: 11.55s, WPM: 103.67\n",
            "Procesando A043.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:10<00:00, 10.57s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A043.wav -> Execution Time: 10.60s, WPM: 131.35\n",
            "Procesando A049.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:07<00:00,  7.53s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A049.wav -> Execution Time: 7.56s, WPM: 139.85\n",
            "Procesando A052.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:05<00:00,  5.58s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A052.wav -> Execution Time: 5.61s, WPM: 148.22\n",
            "Procesando A050.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:06<00:00,  6.65s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A050.wav -> Execution Time: 6.69s, WPM: 150.67\n",
            "Procesando A051.wav con NeMo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:11<00:00, 11.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NeMo STT | A051.wav -> Execution Time: 11.72s, WPM: 160.61\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import nemo.collections.asr as nemo_asr\n",
        "import os\n",
        "import time\n",
        "import torchaudio\n",
        "\n",
        "# 📌 Directorios\n",
        "AUDIO_DIR = \"/content/drive/MyDrive/Transcripcion/Audios\"\n",
        "RESULTS_DIR = \"/content/drive/MyDrive/Transcripcion/Resultados/Nemo\"\n",
        "\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "# 📌 Cargar el modelo NeMo en español\n",
        "print(\"Cargando modelo NeMo STT en español...\")\n",
        "asr_model = nemo_asr.models.EncDecRNNTBPEModel.from_pretrained(model_name=\"stt_es_conformer_transducer_large\")\n",
        "\n",
        "\n",
        "# 📌 Función para calcular palabras por minuto (WPM)\n",
        "def words_per_minute(transcript_text, audio_path):\n",
        "    num_words = len(transcript_text.split())\n",
        "    audio_info = torchaudio.info(audio_path)\n",
        "    duration = audio_info.num_frames / audio_info.sample_rate\n",
        "    return num_words / (duration / 60) if duration > 0 else 0\n",
        "\n",
        "\n",
        "# 📌 Procesar audios con NeMo STT\n",
        "for audio_file in os.listdir(AUDIO_DIR):\n",
        "    if audio_file.endswith(\".wav\"):\n",
        "        audio_path = os.path.join(AUDIO_DIR, audio_file)\n",
        "        transcript_file = os.path.join(RESULTS_DIR, audio_file.replace(\".wav\", \"_T_NM.txt\"))\n",
        "        metrics_file = os.path.join(RESULTS_DIR, audio_file.replace(\".wav\", \"_Metrics.txt\"))\n",
        "\n",
        "        print(f\"Procesando {audio_file} con NeMo...\")\n",
        "\n",
        "        # ⏳ Medir tiempo de ejecución\n",
        "        start_time = time.time()\n",
        "        hypothesis = asr_model.transcribe([audio_path])[0]  # Obtiene el objeto Hypothesis\n",
        "        execution_time = time.time() - start_time\n",
        "\n",
        "        # 📜 Extraer solo el texto de la transcripción\n",
        "        transcript_text = hypothesis.text if hasattr(hypothesis, \"text\") else str(hypothesis)\n",
        "\n",
        "        # 📝 Guardar transcripción\n",
        "        with open(transcript_file, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(transcript_text)\n",
        "\n",
        "        # ⚡ Calcular WPM\n",
        "        wpm = words_per_minute(transcript_text, audio_path)\n",
        "\n",
        "        # 📊 Guardar métricas\n",
        "        with open(metrics_file, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(f\"Execution Time (s): {execution_time:.2f}\\n\")\n",
        "            f.write(f\"WPM: {wpm:.2f}\\n\")\n",
        "\n",
        "        print(f\"✅ NeMo STT | {audio_file} -> Execution Time: {execution_time:.2f}s, WPM: {wpm:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9P4A7Jf_Dwym"
      },
      "source": [
        "## Kaldi Complete\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IIPBnPgxD6sR"
      },
      "outputs": [],
      "source": [
        "# Instalar Vosk y dependencias\n",
        "%%capture\n",
        "!pip install vosk\n",
        "!apt-get install ffmpeg -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tw7fasszDy65",
        "outputId": "9c2f511c-7514-44b8-bf7a-94926bb76bb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-03-18 21:03:46--  https://alphacephei.com/vosk/models/vosk-model-es-0.42.zip\n",
            "Resolving alphacephei.com (alphacephei.com)... 188.40.21.16, 2a01:4f8:13a:279f::2\n",
            "Connecting to alphacephei.com (alphacephei.com)|188.40.21.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1484681703 (1.4G) [application/zip]\n",
            "Saving to: ‘vosk-model-es-0.42.zip’\n",
            "\n",
            "vosk-model-es-0.42. 100%[===================>]   1.38G  30.1MB/s    in 48s     \n",
            "\n",
            "2025-03-18 21:04:34 (29.8 MB/s) - ‘vosk-model-es-0.42.zip’ saved [1484681703/1484681703]\n",
            "\n",
            "Archive:  vosk-model-es-0.42.zip\n",
            "   creating: vosk-model-es-0.42/\n",
            "   creating: vosk-model-es-0.42/graph/\n",
            "  inflating: vosk-model-es-0.42/graph/words.txt  \n",
            "   creating: vosk-model-es-0.42/graph/phones/\n",
            "  inflating: vosk-model-es-0.42/graph/phones/word_boundary.int  \n",
            "  inflating: vosk-model-es-0.42/graph/HCLG.fst  \n",
            "   creating: vosk-model-es-0.42/am/\n",
            "  inflating: vosk-model-es-0.42/am/final.mdl  \n",
            "   creating: vosk-model-es-0.42/rnnlm/\n",
            " extracting: vosk-model-es-0.42/rnnlm/oov.txt  \n",
            "  inflating: vosk-model-es-0.42/rnnlm/special_symbol_opts.conf  \n",
            "  inflating: vosk-model-es-0.42/rnnlm/features.txt  \n",
            "  inflating: vosk-model-es-0.42/rnnlm/final.raw  \n",
            "  inflating: vosk-model-es-0.42/rnnlm/special_symbol_opts.txt  \n",
            "  inflating: vosk-model-es-0.42/rnnlm/feat_embedding.final.mat  \n",
            "  inflating: vosk-model-es-0.42/rnnlm/word_feats.txt  \n",
            "  inflating: vosk-model-es-0.42/README  \n",
            "   creating: vosk-model-es-0.42/rescore/\n",
            "  inflating: vosk-model-es-0.42/rescore/G.fst  \n",
            "  inflating: vosk-model-es-0.42/rescore/G.carpa  \n",
            "   creating: vosk-model-es-0.42/conf/\n",
            "  inflating: vosk-model-es-0.42/conf/model.conf  \n",
            "  inflating: vosk-model-es-0.42/conf/mfcc.conf  \n",
            "   creating: vosk-model-es-0.42/ivector/\n",
            "  inflating: vosk-model-es-0.42/ivector/final.dubm  \n",
            "  inflating: vosk-model-es-0.42/ivector/global_cmvn.stats  \n",
            "  inflating: vosk-model-es-0.42/ivector/final.ie  \n",
            "  inflating: vosk-model-es-0.42/ivector/final.mat  \n",
            "  inflating: vosk-model-es-0.42/ivector/splice.conf  \n",
            " extracting: vosk-model-es-0.42/ivector/online_cmvn.conf  \n",
            "🎤 Kaldi | Audio: A001.wav -> Execution Time: 12.12s, WPM: 85.83\n",
            "🎤 Kaldi | Audio: A002.wav -> Execution Time: 7.52s, WPM: 90.11\n",
            "🎤 Kaldi | Audio: A003.wav -> Execution Time: 6.73s, WPM: 94.93\n",
            "🎤 Kaldi | Audio: A004.wav -> Execution Time: 42.21s, WPM: 119.98\n",
            "🎤 Kaldi | Audio: A005.wav -> Execution Time: 21.57s, WPM: 117.60\n",
            "🎤 Kaldi | Audio: A006.wav -> Execution Time: 58.45s, WPM: 130.42\n",
            "🎤 Kaldi | Audio: A007.wav -> Execution Time: 7.89s, WPM: 56.91\n",
            "🎤 Kaldi | Audio: A008.wav -> Execution Time: 9.44s, WPM: 121.82\n",
            "🎤 Kaldi | Audio: A009.wav -> Execution Time: 15.11s, WPM: 147.66\n",
            "🎤 Kaldi | Audio: A010.wav -> Execution Time: 9.86s, WPM: 97.64\n",
            "🎤 Kaldi | Audio: A011.wav -> Execution Time: 20.74s, WPM: 141.89\n",
            "🎤 Kaldi | Audio: A012.wav -> Execution Time: 21.12s, WPM: 113.94\n",
            "🎤 Kaldi | Audio: A013.wav -> Execution Time: 31.76s, WPM: 144.25\n",
            "🎤 Kaldi | Audio: A014.wav -> Execution Time: 39.07s, WPM: 147.47\n",
            "🎤 Kaldi | Audio: A015.wav -> Execution Time: 31.29s, WPM: 125.17\n",
            "🎤 Kaldi | Audio: A016.wav -> Execution Time: 20.37s, WPM: 121.65\n",
            "🎤 Kaldi | Audio: A017.wav -> Execution Time: 26.76s, WPM: 89.50\n",
            "🎤 Kaldi | Audio: A018.wav -> Execution Time: 37.83s, WPM: 132.03\n",
            "🎤 Kaldi | Audio: A019.wav -> Execution Time: 18.42s, WPM: 124.38\n",
            "🎤 Kaldi | Audio: A020.wav -> Execution Time: 10.76s, WPM: 141.68\n",
            "🎤 Kaldi | Audio: A021.wav -> Execution Time: 9.58s, WPM: 43.15\n",
            "🎤 Kaldi | Audio: A022.wav -> Execution Time: 11.89s, WPM: 143.92\n",
            "🎤 Kaldi | Audio: A023.wav -> Execution Time: 18.16s, WPM: 98.27\n",
            "🎤 Kaldi | Audio: A024.wav -> Execution Time: 12.50s, WPM: 148.91\n",
            "🎤 Kaldi | Audio: A025.wav -> Execution Time: 8.80s, WPM: 89.59\n",
            "🎤 Kaldi | Audio: A026.wav -> Execution Time: 13.39s, WPM: 166.10\n",
            "🎤 Kaldi | Audio: A027.wav -> Execution Time: 10.44s, WPM: 110.98\n",
            "🎤 Kaldi | Audio: A028.wav -> Execution Time: 12.08s, WPM: 111.53\n",
            "🎤 Kaldi | Audio: A029.wav -> Execution Time: 11.87s, WPM: 98.37\n",
            "🎤 Kaldi | Audio: A030.wav -> Execution Time: 11.49s, WPM: 119.36\n",
            "🎤 Kaldi | Audio: A031.wav -> Execution Time: 11.24s, WPM: 88.75\n",
            "🎤 Kaldi | Audio: A032.wav -> Execution Time: 13.47s, WPM: 142.95\n",
            "🎤 Kaldi | Audio: A033.wav -> Execution Time: 9.05s, WPM: 53.74\n",
            "🎤 Kaldi | Audio: A034.wav -> Execution Time: 21.79s, WPM: 89.02\n",
            "🎤 Kaldi | Audio: A035.wav -> Execution Time: 8.51s, WPM: 76.14\n",
            "🎤 Kaldi | Audio: A036.wav -> Execution Time: 5.30s, WPM: 0.00\n",
            "🎤 Kaldi | Audio: A037.wav -> Execution Time: 5.23s, WPM: 34.57\n",
            "🎤 Kaldi | Audio: A038.wav -> Execution Time: 3.47s, WPM: 0.00\n",
            "🎤 Kaldi | Audio: A039.wav -> Execution Time: 5.46s, WPM: 0.00\n",
            "🎤 Kaldi | Audio: A040.wav -> Execution Time: 20.87s, WPM: 119.49\n",
            "🎤 Kaldi | Audio: A041.wav -> Execution Time: 13.73s, WPM: 127.13\n",
            "🎤 Kaldi | Audio: A042.wav -> Execution Time: 11.91s, WPM: 126.42\n",
            "🎤 Kaldi | Audio: A043.wav -> Execution Time: 10.15s, WPM: 134.76\n",
            "🎤 Kaldi | Audio: A044.wav -> Execution Time: 12.34s, WPM: 109.68\n",
            "🎤 Kaldi | Audio: A045.wav -> Execution Time: 7.57s, WPM: 144.37\n",
            "🎤 Kaldi | Audio: A046.wav -> Execution Time: 6.98s, WPM: 154.89\n",
            "🎤 Kaldi | Audio: A047.wav -> Execution Time: 10.93s, WPM: 102.42\n",
            "🎤 Kaldi | Audio: A048.wav -> Execution Time: 8.27s, WPM: 126.30\n",
            "🎤 Kaldi | Audio: A049.wav -> Execution Time: 8.45s, WPM: 113.77\n",
            "🎤 Kaldi | Audio: A050.wav -> Execution Time: 8.70s, WPM: 35.16\n",
            "🎤 Kaldi | Audio: A051.wav -> Execution Time: 4.86s, WPM: 0.00\n",
            "🎤 Kaldi | Audio: A052.wav -> Execution Time: 7.82s, WPM: 135.22\n",
            "🎤 Kaldi | Audio: A053.wav -> Execution Time: 9.06s, WPM: 56.98\n",
            "🎤 Kaldi | Audio: A054.wav -> Execution Time: 9.75s, WPM: 51.12\n",
            "🎤 Kaldi | Audio: A055.wav -> Execution Time: 11.73s, WPM: 88.46\n",
            "🎤 Kaldi | Audio: A056.wav -> Execution Time: 14.43s, WPM: 82.41\n",
            "🎤 Kaldi | Audio: A057.wav -> Execution Time: 18.67s, WPM: 101.66\n",
            "🎤 Kaldi | Audio: A058.wav -> Execution Time: 10.71s, WPM: 84.86\n",
            "🎤 Kaldi | Audio: A059.wav -> Execution Time: 18.86s, WPM: 131.37\n",
            "🎤 Kaldi | Audio: A060.wav -> Execution Time: 24.57s, WPM: 148.48\n",
            "🎤 Kaldi | Audio: A061.wav -> Execution Time: 14.52s, WPM: 99.17\n",
            "🎤 Kaldi | Audio: A062.wav -> Execution Time: 11.63s, WPM: 119.21\n",
            "🎤 Kaldi | Audio: A063.wav -> Execution Time: 10.75s, WPM: 111.12\n",
            "🎤 Kaldi | Audio: A064.wav -> Execution Time: 14.55s, WPM: 154.98\n",
            "🎤 Kaldi | Audio: A065.wav -> Execution Time: 8.42s, WPM: 81.69\n",
            "🎤 Kaldi | Audio: A066.wav -> Execution Time: 10.07s, WPM: 39.25\n",
            "🎤 Kaldi | Audio: A067.wav -> Execution Time: 16.98s, WPM: 69.89\n",
            "🎤 Kaldi | Audio: A068.wav -> Execution Time: 7.77s, WPM: 54.81\n",
            "🎤 Kaldi | Audio: A069.wav -> Execution Time: 14.80s, WPM: 74.71\n"
          ]
        }
      ],
      "source": [
        "# Importar librerías necesarias\n",
        "import os\n",
        "import time\n",
        "import wave\n",
        "import json\n",
        "import subprocess\n",
        "from vosk import Model, KaldiRecognizer\n",
        "\n",
        "# Definir rutas\n",
        "AUDIO_DIR = \"/content/drive/MyDrive/Transcripcion/Audios\"\n",
        "RESULTS_DIR = \"/content/drive/MyDrive/Transcripcion/Resultados\"\n",
        "MODEL_NAME = \"Kaldi_Vosk_Complete\"  # Nombre del modelo para organizar resultados\n",
        "MODEL_DIR = os.path.join(RESULTS_DIR, MODEL_NAME)\n",
        "\n",
        "# Crear carpeta de resultados si no existe\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "# Descargar modelo de Vosk más grande si no existe\n",
        "if not os.path.exists(\"model\"):\n",
        "    !wget https://alphacephei.com/vosk/models/vosk-model-es-0.42.zip\n",
        "    !unzip vosk-model-es-0.42.zip\n",
        "    !mv vosk-model-es-0.42 model\n",
        "\n",
        "# Cargar el modelo de Vosk\n",
        "model = Model(\"model\")\n",
        "\n",
        "# Función para convertir audios a PCM 16-bit mono\n",
        "def convert_to_pcm16(audio_path):\n",
        "    output_path = audio_path.replace(\".wav\", \"_converted.wav\")\n",
        "    command = f\"ffmpeg -i {audio_path} -ac 1 -ar 16000 -sample_fmt s16 {output_path} -y\"\n",
        "    subprocess.run(command, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "    return output_path\n",
        "\n",
        "# Función para calcular Words Per Minute (WPM)\n",
        "def words_per_minute(text, audio_path):\n",
        "    with wave.open(audio_path, \"rb\") as wf:\n",
        "        duration = wf.getnframes() / wf.getframerate()  # Duración en segundos\n",
        "    words = len(text.split())\n",
        "    return (words / duration) * 60 if duration > 0 else 0\n",
        "\n",
        "# Función para transcribir audio\n",
        "def transcribir_audio(ruta_audio):\n",
        "    with wave.open(ruta_audio, \"rb\") as wf:\n",
        "        if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getcomptype() != \"NONE\":\n",
        "            print(f\"🔄 Convertiendo formato: {ruta_audio}\")\n",
        "            ruta_audio = convert_to_pcm16(ruta_audio)  # Convertir si no es PCM 16-bit mono\n",
        "\n",
        "        recognizer = KaldiRecognizer(model, wf.getframerate())\n",
        "        texto_transcrito = \"\"\n",
        "\n",
        "        while True:\n",
        "            data = wf.readframes(4000)\n",
        "            if len(data) == 0:\n",
        "                break\n",
        "            if recognizer.AcceptWaveform(data):\n",
        "                result = json.loads(recognizer.Result())\n",
        "                texto_transcrito += result.get(\"text\", \"\") + \" \"\n",
        "\n",
        "        return texto_transcrito.strip()\n",
        "\n",
        "# Procesar audios\n",
        "for audio_file in sorted(os.listdir(AUDIO_DIR)):  # Ordenar para asegurar el orden correcto\n",
        "    if audio_file.endswith(\".wav\"):\n",
        "        audio_path = os.path.join(AUDIO_DIR, audio_file)\n",
        "        transcript_file = os.path.join(MODEL_DIR, audio_file.replace(\".wav\", \"_T_K.txt\"))\n",
        "        metrics_file = os.path.join(MODEL_DIR, audio_file.replace(\".wav\", \"_Metrics.txt\"))\n",
        "\n",
        "        # Verificar si ya existe la transcripción\n",
        "        if os.path.exists(transcript_file):\n",
        "            print(f\"✅ Ya existe transcripción para: {audio_file}\")\n",
        "            continue  # Saltar este archivo\n",
        "\n",
        "        try:\n",
        "            # Transcripción y medición de tiempo\n",
        "            start_time = time.time()\n",
        "            transcript = transcribir_audio(audio_path)\n",
        "            execution_time = time.time() - start_time\n",
        "\n",
        "            # Calcular WPM\n",
        "            wpm = words_per_minute(transcript, audio_path)\n",
        "\n",
        "            # Guardar transcripción\n",
        "            with open(transcript_file, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(transcript)\n",
        "\n",
        "            # Guardar métricas\n",
        "            with open(metrics_file, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(f\"Execution Time (s): {execution_time:.2f}\\n\")\n",
        "                f.write(f\"WPM: {wpm:.2f}\\n\")\n",
        "\n",
        "            print(f\"🎤 Kaldi | Audio: {audio_file} -> Execution Time: {execution_time:.2f}s, WPM: {wpm:.2f}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error procesando {audio_file}: {e}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03798385c704408a910d6d41adc3abfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86f22ad4d0244d70bddf66de773a2439",
            "max": 163,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_30dfd16c6c3a45d1aa056e56b747d9d3",
            "value": 163
          }
        },
        "03991ffcd8bd43c0bcb3af0fae337ef6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05beee139a96471eb791afbcd0e2c297": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08e5bde1eac146f7bc529dc2c38aa900": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e4cf93f723564111b07399e6ea70e40b",
              "IPY_MODEL_228ebead60a24a28b92703d0443cfdc4",
              "IPY_MODEL_97fc1044d51a44a299c634a8a2997c61"
            ],
            "layout": "IPY_MODEL_6b1358a1191849f49aebad0201923634"
          }
        },
        "0e5ccb39e7e64a8aafc7f4d15814720f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "14538a2040fc4a3a9b1f094607b6b996": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1528432236f04f74b83c3ed6b166b279": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98ec7a46035945c48054ffc309985527",
            "placeholder": "​",
            "style": "IPY_MODEL_cad32b63421b412a9cb3769802797b38",
            "value": " 159/159 [00:00&lt;00:00, 10.8kB/s]"
          }
        },
        "194b3df33634426da5b0e2d0158cf490": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "194bd6d13ef84d21a7bf59287400865b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a1bdeeeabdf437bb224e56b39516e5a",
            "placeholder": "​",
            "style": "IPY_MODEL_bb6fc18ea0d94262910caad9b7be4290",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "1d6cb84e65eb4a10a66e7fb8bb8f98b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_194b3df33634426da5b0e2d0158cf490",
            "placeholder": "​",
            "style": "IPY_MODEL_f50a7ea750a34800b57def6e742b246d",
            "value": "Loading checkpoint shards:  40%"
          }
        },
        "1f7ed628fd3948409b560902a99cfa0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5a0a98be17a4d63b0f8f9d8deaa3dad",
            "placeholder": "​",
            "style": "IPY_MODEL_9fcf7eb415a24345b3b9c7add1a1f8d0",
            "value": "model.safetensors: 100%"
          }
        },
        "228ebead60a24a28b92703d0443cfdc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de4b539ca9274aea9c31de4feb37af0b",
            "max": 291,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f2b80bf9c9a347858dc244986f31fccc",
            "value": 291
          }
        },
        "2aee8d9ec8d64748bddae7dca2c3de0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f5f22ab784f42a7b2fab8533c0c61fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d0a698cd743495e8ec2b120954e4cc6",
              "IPY_MODEL_c87ea1624dea40d1973a2fcfae79b14b",
              "IPY_MODEL_ea6dc050287b4699a16a7ac1c3364aaa"
            ],
            "layout": "IPY_MODEL_f8be9eb33c724915b64d15989f2e30e4"
          }
        },
        "30dfd16c6c3a45d1aa056e56b747d9d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "33da0991344944acab9b2159bdc88aff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_194bd6d13ef84d21a7bf59287400865b",
              "IPY_MODEL_03798385c704408a910d6d41adc3abfb",
              "IPY_MODEL_aa3d6e0b36d941fba5956774a0691fea"
            ],
            "layout": "IPY_MODEL_03991ffcd8bd43c0bcb3af0fae337ef6"
          }
        },
        "3911059689f84af1ab0bc3ecf78a0060": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_482f613250104e0cbfc400576a12a784",
            "placeholder": "​",
            "style": "IPY_MODEL_b156b2fd61a34186a72ba599d34b7b48",
            "value": "config.json: 100%"
          }
        },
        "41ceb22e40c24b7a80ef21685ff5fa5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45f8289ba7c347508a2b56aaf9096c36": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47c9a29a824c4d1fae06f6f23d3ce4d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "482f613250104e0cbfc400576a12a784": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "557d8ed4847e4e1888438b86af4f9da7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "592566b0b3b64a618adbdb9af05fabdb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59b5471b57674d9a9ea17401ebd4d94e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a1bdeeeabdf437bb224e56b39516e5a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "653e670088174ba0aceb32497f3ce003": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "667ab26e7846467f872974ea9d42006b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "693f5302799846ec8858052ea3cb9276": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6b1358a1191849f49aebad0201923634": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bdf001617ab4aa496566aabd3143f02": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e881b47ee9a40088c83247cf0383c28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_592566b0b3b64a618adbdb9af05fabdb",
            "placeholder": "​",
            "style": "IPY_MODEL_14538a2040fc4a3a9b1f094607b6b996",
            "value": " 1.60k/1.60k [00:00&lt;00:00, 103kB/s]"
          }
        },
        "72ea22fa475740a5b0beace38649bf5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_557d8ed4847e4e1888438b86af4f9da7",
            "max": 159,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_693f5302799846ec8858052ea3cb9276",
            "value": 159
          }
        },
        "73d6f7de25804145a89c76523a07425a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_653e670088174ba0aceb32497f3ce003",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ae5734e9a90b4966bc6a70f71ae76d55",
            "value": 2
          }
        },
        "74856582a4034e7a9257d050aa51f632": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7710df23feed4dbda6fcc62721d03979": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f28eff8b68c4ca1af530b66c61995eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80b335ad74a944d899d4c60a1f8349a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c80069d5cf8245f9b93337050bb61bc1",
            "max": 1596,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_96d74a9710f64a6ca9ca7fc9699f7071",
            "value": 1596
          }
        },
        "818d38e5af6445e2bfcc10ba7b41bccc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85e8e10da2dd45f1bb4332598f756bac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86f22ad4d0244d70bddf66de773a2439": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94869d5629e4424aab5e6830c03e4647": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96d74a9710f64a6ca9ca7fc9699f7071": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97858d6e146e42c7be2d908b96e61304": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97fc1044d51a44a299c634a8a2997c61": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94869d5629e4424aab5e6830c03e4647",
            "placeholder": "​",
            "style": "IPY_MODEL_97858d6e146e42c7be2d908b96e61304",
            "value": " 291/291 [00:00&lt;00:00, 18.9kB/s]"
          }
        },
        "98ec7a46035945c48054ffc309985527": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d0a698cd743495e8ec2b120954e4cc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_818d38e5af6445e2bfcc10ba7b41bccc",
            "placeholder": "​",
            "style": "IPY_MODEL_2aee8d9ec8d64748bddae7dca2c3de0b",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "9ebe815100df4495b1f35ec1aa3e1879": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1f7ed628fd3948409b560902a99cfa0b",
              "IPY_MODEL_c99792be442b4e22a56f4ffefb4bfcd5",
              "IPY_MODEL_d0e67cbe3454421c92ac8d5ae4223d19"
            ],
            "layout": "IPY_MODEL_ff45379e0e9d4ddaa966bdd18cb976a6"
          }
        },
        "9fcf7eb415a24345b3b9c7add1a1f8d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9394fbcfd7e41b89013e3be1e3283e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3911059689f84af1ab0bc3ecf78a0060",
              "IPY_MODEL_80b335ad74a944d899d4c60a1f8349a2",
              "IPY_MODEL_6e881b47ee9a40088c83247cf0383c28"
            ],
            "layout": "IPY_MODEL_f3e12b8082bb40afac5cd499e4bcfb9c"
          }
        },
        "aa3d6e0b36d941fba5956774a0691fea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47c9a29a824c4d1fae06f6f23d3ce4d4",
            "placeholder": "​",
            "style": "IPY_MODEL_7f28eff8b68c4ca1af530b66c61995eb",
            "value": " 163/163 [00:00&lt;00:00, 12.8kB/s]"
          }
        },
        "ae5734e9a90b4966bc6a70f71ae76d55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af1425e73e4d4227b8c44e7868b9beb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85e8e10da2dd45f1bb4332598f756bac",
            "placeholder": "​",
            "style": "IPY_MODEL_f12ee3822594491099cd3a69d813ae72",
            "value": " 2/5 [00:46&lt;01:09, 23.17s/it]"
          }
        },
        "b156b2fd61a34186a72ba599d34b7b48": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba97c83734904d4f846d3c6751821af8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1d6cb84e65eb4a10a66e7fb8bb8f98b8",
              "IPY_MODEL_73d6f7de25804145a89c76523a07425a",
              "IPY_MODEL_af1425e73e4d4227b8c44e7868b9beb7"
            ],
            "layout": "IPY_MODEL_da41ecc2636b4ac1b831d22f8ed6a3c8"
          }
        },
        "bb6fc18ea0d94262910caad9b7be4290": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf95f0813ec24383a64f51de7e1bcb3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d5342f87343d4ccfa8c820a5b63156b3",
              "IPY_MODEL_72ea22fa475740a5b0beace38649bf5d",
              "IPY_MODEL_1528432236f04f74b83c3ed6b166b279"
            ],
            "layout": "IPY_MODEL_667ab26e7846467f872974ea9d42006b"
          }
        },
        "c80069d5cf8245f9b93337050bb61bc1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c87ea1624dea40d1973a2fcfae79b14b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59b5471b57674d9a9ea17401ebd4d94e",
            "max": 85,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e5c42b4779fc48cd92bf8aed0af18d44",
            "value": 85
          }
        },
        "c99792be442b4e22a56f4ffefb4bfcd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6f6777bba914442acd2f549766e2370",
            "max": 377607901,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0e5ccb39e7e64a8aafc7f4d15814720f",
            "value": 377607901
          }
        },
        "cad32b63421b412a9cb3769802797b38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0e67cbe3454421c92ac8d5ae4223d19": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7710df23feed4dbda6fcc62721d03979",
            "placeholder": "​",
            "style": "IPY_MODEL_74856582a4034e7a9257d050aa51f632",
            "value": " 378M/378M [00:04&lt;00:00, 79.6MB/s]"
          }
        },
        "d5342f87343d4ccfa8c820a5b63156b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45f8289ba7c347508a2b56aaf9096c36",
            "placeholder": "​",
            "style": "IPY_MODEL_f8eb500ab5274c008172b38e1d82a63f",
            "value": "preprocessor_config.json: 100%"
          }
        },
        "da41ecc2636b4ac1b831d22f8ed6a3c8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de4b539ca9274aea9c31de4feb37af0b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4cf93f723564111b07399e6ea70e40b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05beee139a96471eb791afbcd0e2c297",
            "placeholder": "​",
            "style": "IPY_MODEL_6bdf001617ab4aa496566aabd3143f02",
            "value": "vocab.json: 100%"
          }
        },
        "e5a0a98be17a4d63b0f8f9d8deaa3dad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5c42b4779fc48cd92bf8aed0af18d44": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e6f6777bba914442acd2f549766e2370": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e72fba52b45846709c95e210d5f8b5ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea6dc050287b4699a16a7ac1c3364aaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e72fba52b45846709c95e210d5f8b5ca",
            "placeholder": "​",
            "style": "IPY_MODEL_41ceb22e40c24b7a80ef21685ff5fa5e",
            "value": " 85.0/85.0 [00:00&lt;00:00, 5.94kB/s]"
          }
        },
        "f12ee3822594491099cd3a69d813ae72": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2b80bf9c9a347858dc244986f31fccc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f3e12b8082bb40afac5cd499e4bcfb9c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f50a7ea750a34800b57def6e742b246d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8be9eb33c724915b64d15989f2e30e4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8eb500ab5274c008172b38e1d82a63f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff45379e0e9d4ddaa966bdd18cb976a6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}